{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"CEDS KMeans","text":""},{"location":"#base-class","title":"Base Class","text":""},{"location":"#cedskmeans._cedskmeans.CEDSKMeans","title":"<code>CEDSKMeans</code>","text":"<p>               Bases: <code>KMeans</code></p> <p>Differentially private k-means clustering.</p> <p>Read more in [1].</p> <p>Parameters:</p> Name Type Description Default <code>n_clusters</code> <code>int</code> <p>Refer to [2]. Defaults to 8.</p> <code>8</code> <code>dp_epsilon</code> <code>float</code> <p>The differential privacy parameter epsilon [1]. Defaults to 0.1.</p> <code>0.1</code> <code>dp_delta</code> <code>float</code> <p>The differential private parameter delta [1]. Defaults to 0.1.</p> <code>0.1</code> <code>init</code> <code>Literal[\"random\", \"k-means++\"</code> <p>Refer to [2]. Defaults to \u201ck-means++\u201d.</p> <code>'k-means++'</code> <code>n_init</code> <code>str | int</code> <p>Refer to [2]. Defaults to \u201cwarn\u201d.</p> <code>'warn'</code> <code>max_iter</code> <code>int</code> <p>Refer to [2]. Defaults to 300.</p> <code>300</code> <code>tol</code> <code>float</code> <p>Refer to [2]. Defaults to 1e-4.</p> <code>0.0001</code> <code>verbose</code> <code>int</code> <p>Refer to [2]. Defaults to 0.</p> <code>0</code> <code>random_state</code> <code>int</code> <p>Refer to [2]. Defaults to None.</p> <code>None</code> <code>copy_x</code> <code>bool</code> <p>Refer to [2]. Defaults to True.</p> <code>True</code> <code>algorithm</code> <code>Literal['lloyd', 'elkan', 'auto', 'full']</code> <p>Refer to [2]. Defaults to \u201clloyd\u201d.</p> <code>'lloyd'</code> Source code in <code>src/cedskmeans/_cedskmeans.py</code> <pre><code>class CEDSKMeans(KMeans):\n    \"\"\"Differentially private k-means clustering.\n\n    Read more in [1].\n\n    Args:\n        n_clusters (int, optional): Refer to [2]. Defaults to 8.\n        dp_epsilon (float, optional): The differential privacy parameter epsilon [1]. Defaults to 0.1.\n        dp_delta (float, optional): The differential private parameter delta [1]. Defaults to 0.1.\n        init (Literal[\"random\", \"k-means++\", optional): Refer to [2]. Defaults to \"k-means++\".\n        n_init (str | int, optional): Refer to [2]. Defaults to \"warn\".\n        max_iter (int, optional): Refer to [2]. Defaults to 300.\n        tol (float, optional): Refer to [2]. Defaults to 1e-4.\n        verbose (int, optional): Refer to [2]. Defaults to 0.\n        random_state (int, optional): Refer to [2]. Defaults to None.\n        copy_x (bool, optional): Refer to [2]. Defaults to True.\n        algorithm (Literal[\"lloyd\", \"elkan\", \"auto\", \"full\"], optional): Refer to [2]. Defaults to \"lloyd\".\n    \"\"\"\n\n    def __init__(\n        self,\n        n_clusters: int = 8,\n        dp_epsilon: float = 0.1,\n        dp_delta: float = 0.1,\n        *,\n        init: Literal[\"random\", \"k-means++\"] = \"k-means++\",\n        n_init: str | int = \"warn\",\n        max_iter: int = 300,\n        tol: float = 1e-4,\n        verbose: int = 0,\n        random_state: int = None,\n        copy_x: bool = True,\n        algorithm: Literal[\"lloyd\", \"elkan\", \"auto\", \"full\"] = \"lloyd\",\n    ):\n        super().__init__(\n            n_clusters=n_clusters,\n            init=init,\n            n_init=n_init,\n            max_iter=max_iter,\n            tol=tol,\n            verbose=verbose,\n            random_state=random_state,\n            copy_x=copy_x,\n            algorithm=algorithm,\n        )\n\n        self.dp_epsilon = dp_epsilon\n        self.dp_delta = dp_delta\n\n    def _add_dp_noise(self, X: npt.NDArray) -&gt; npt.NDArray:\n        \"\"\"Adds differential private noise to the cluster centers.\n\n        Args:\n            X (npt.NDArray): Training instances to cluster  of shape (n_samples, n_features).\n        \"\"\"\n        self.color_cov = self._calculate_color_noise_covariance(X)\n        self.cluster_centers_ = (\n            self.true_cluster_centers_\n            + np.random.multivariate_normal(\n                np.zeros(self.n_clusters * X.shape[1]), self.color_cov\n            ).reshape(self.n_clusters, X.shape[1])\n        )\n        self.labels_ = self.true_labels_\n\n    def _calculate_color_noise_covariance(self, X: npt.NDArray) -&gt; npt.NDArray:\n        \"\"\"Calculates the differentially private color noise covariance matrix [1].\n\n        Args:\n            X (npt.NDArray): Training instances to cluster. Of shape (n_samples, n_features).Training instances to cluster. It must be noted that the data will be converted to C ordering, which will cause a memory copy if the given data is not C-contiguous. If a sparse matrix is passed, a copy will be made if it's not in CSR format.\n\n        Returns:\n            npt.NDArray: DP covariance matrix of shape (n_clusters * n_features, n_clusters * n_features).\n\n        [1] Ravi, Nikhil, Anna Scaglione, and Sean Peisert.\n        \"Colored noise mechanism for differentially private clustering.\" (2021).\n        https://arxiv.org/pdf/2006.03684.pdf\n        \"\"\"\n\n        cluster_cardinality = _cluster_cardinality(self.true_labels_, self.n_clusters)\n        cluster_sum = _cluster_sum(X, self.true_labels_, self.n_clusters)\n        cluster_center_without_node = _cluster_center_without_node(\n            X, self.true_labels_, cluster_sum, cluster_cardinality\n        )\n        modified_cluster_centers = _modified_cluster_centers(\n            X,\n            self.true_cluster_centers_,\n            self.true_labels_,\n            cluster_center_without_node,\n        )\n        change_in_cluster_centers = (\n            self.true_cluster_centers_.reshape(-1, 1) - modified_cluster_centers\n        )  # Form the $\\bm{C}_{XX'}$ matrix\n\n        sorted_change_in_cluster_centers = _sort_columns_by_norm(\n            change_in_cluster_centers\n        )\n        independent_columns = _find_independent_columns(\n            sorted_change_in_cluster_centers\n        )\n        independent_columns_T = _svd_transpose(independent_columns)\n\n        dp_epsilon_total = self.dp_epsilon * self.n_clusters * X.shape[1]\n        gamma_c = dp_epsilon_total**2 / (2 * np.log(2 / self.dp_delta))\n\n        lambda_star = _calculate_langrange_multiplier(independent_columns_T, gamma_c)\n        R_lambda_star = _calculate_objective_function(independent_columns, lambda_star)\n\n        dp_color_covariance = _calculate_color_noise_covariance(R_lambda_star)\n        return dp_color_covariance\n</code></pre>"},{"location":"#cedskmeans._cedskmeans.CEDSKMeans._add_dp_noise","title":"<code>_add_dp_noise(X)</code>","text":"<p>Adds differential private noise to the cluster centers.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>NDArray</code> <p>Training instances to cluster  of shape (n_samples, n_features).</p> required Source code in <code>src/cedskmeans/_cedskmeans.py</code> <pre><code>def _add_dp_noise(self, X: npt.NDArray) -&gt; npt.NDArray:\n    \"\"\"Adds differential private noise to the cluster centers.\n\n    Args:\n        X (npt.NDArray): Training instances to cluster  of shape (n_samples, n_features).\n    \"\"\"\n    self.color_cov = self._calculate_color_noise_covariance(X)\n    self.cluster_centers_ = (\n        self.true_cluster_centers_\n        + np.random.multivariate_normal(\n            np.zeros(self.n_clusters * X.shape[1]), self.color_cov\n        ).reshape(self.n_clusters, X.shape[1])\n    )\n    self.labels_ = self.true_labels_\n</code></pre>"},{"location":"#cedskmeans._cedskmeans.CEDSKMeans._calculate_color_noise_covariance","title":"<code>_calculate_color_noise_covariance(X)</code>","text":"<p>Calculates the differentially private color noise covariance matrix [1].</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>NDArray</code> <p>Training instances to cluster. Of shape (n_samples, n_features).Training instances to cluster. It must be noted that the data will be converted to C ordering, which will cause a memory copy if the given data is not C-contiguous. If a sparse matrix is passed, a copy will be made if it\u2019s not in CSR format.</p> required <p>Returns:</p> Type Description <code>NDArray</code> <p>npt.NDArray: DP covariance matrix of shape (n_clusters * n_features, n_clusters * n_features).</p> <p>[1] Ravi, Nikhil, Anna Scaglione, and Sean Peisert. \u201cColored noise mechanism for differentially private clustering.\u201d (2021). https://arxiv.org/pdf/2006.03684.pdf</p> Source code in <code>src/cedskmeans/_cedskmeans.py</code> <pre><code>def _calculate_color_noise_covariance(self, X: npt.NDArray) -&gt; npt.NDArray:\n    \"\"\"Calculates the differentially private color noise covariance matrix [1].\n\n    Args:\n        X (npt.NDArray): Training instances to cluster. Of shape (n_samples, n_features).Training instances to cluster. It must be noted that the data will be converted to C ordering, which will cause a memory copy if the given data is not C-contiguous. If a sparse matrix is passed, a copy will be made if it's not in CSR format.\n\n    Returns:\n        npt.NDArray: DP covariance matrix of shape (n_clusters * n_features, n_clusters * n_features).\n\n    [1] Ravi, Nikhil, Anna Scaglione, and Sean Peisert.\n    \"Colored noise mechanism for differentially private clustering.\" (2021).\n    https://arxiv.org/pdf/2006.03684.pdf\n    \"\"\"\n\n    cluster_cardinality = _cluster_cardinality(self.true_labels_, self.n_clusters)\n    cluster_sum = _cluster_sum(X, self.true_labels_, self.n_clusters)\n    cluster_center_without_node = _cluster_center_without_node(\n        X, self.true_labels_, cluster_sum, cluster_cardinality\n    )\n    modified_cluster_centers = _modified_cluster_centers(\n        X,\n        self.true_cluster_centers_,\n        self.true_labels_,\n        cluster_center_without_node,\n    )\n    change_in_cluster_centers = (\n        self.true_cluster_centers_.reshape(-1, 1) - modified_cluster_centers\n    )  # Form the $\\bm{C}_{XX'}$ matrix\n\n    sorted_change_in_cluster_centers = _sort_columns_by_norm(\n        change_in_cluster_centers\n    )\n    independent_columns = _find_independent_columns(\n        sorted_change_in_cluster_centers\n    )\n    independent_columns_T = _svd_transpose(independent_columns)\n\n    dp_epsilon_total = self.dp_epsilon * self.n_clusters * X.shape[1]\n    gamma_c = dp_epsilon_total**2 / (2 * np.log(2 / self.dp_delta))\n\n    lambda_star = _calculate_langrange_multiplier(independent_columns_T, gamma_c)\n    R_lambda_star = _calculate_objective_function(independent_columns, lambda_star)\n\n    dp_color_covariance = _calculate_color_noise_covariance(R_lambda_star)\n    return dp_color_covariance\n</code></pre>"},{"location":"#cedskmeans._cedskmeans._calculate_color_noise_covariance","title":"<code>_calculate_color_noise_covariance(matrix)</code>","text":"<p>Calculates the covariance matrix of the colored noise.</p> <p>Parameters:</p> Name Type Description Default <code>matrix</code> <code>NDArray</code> <p>A matrix. Refer to eq. 11 of [1]</p> required <p>Returns:</p> Type Description <code>NDArray</code> <p>npt.NDArray: Covariance matrix of the colored noise.</p> <p>[1] Ravi, Nikhil, Anna Scaglione, and Sean Peisert. \u201cColored noise mechanism for differentially private clustering.\u201d (2021). https://arxiv.org/pdf/2006.03684.pdf</p> Source code in <code>src/cedskmeans/_cedskmeans.py</code> <pre><code>def _calculate_color_noise_covariance(matrix: npt.NDArray) -&gt; npt.NDArray:\n    \"\"\"Calculates the covariance matrix of the colored noise.\n\n    Args:\n        matrix (npt.NDArray): A matrix. Refer to eq. 11 of [1]\n\n    Returns:\n        npt.NDArray: Covariance matrix of the colored noise.\n\n    [1] Ravi, Nikhil, Anna Scaglione, and Sean Peisert.\n    \"Colored noise mechanism for differentially private clustering.\" (2021).\n    https://arxiv.org/pdf/2006.03684.pdf\n    \"\"\"\n    U, D, V = np.linalg.svd(matrix)\n    return U @ np.diag(np.sqrt(D)) @ V\n</code></pre>"},{"location":"#cedskmeans._cedskmeans._calculate_langrange_multiplier","title":"<code>_calculate_langrange_multiplier(matrix, gamma_c)</code>","text":"<p>Calculates the Langrange multiplier.</p> <p>Parameters:</p> Name Type Description Default <code>matrix</code> <code>NDArray</code> <p>A matrix. Refer to eq. 22 of [1]</p> required <code>gamma_c</code> <code>float</code> <p>Differential privacy parameter.</p> required <p>Returns:</p> Type Description <code>NDArray</code> <p>npt.NDArray: Langrange multiplier.</p> <p>[1] Ravi, Nikhil, Anna Scaglione, and Sean Peisert. \u201cColored noise mechanism for differentially private clustering.\u201d (2021). https://arxiv.org/pdf/2006.03684.pdf</p> Source code in <code>src/cedskmeans/_cedskmeans.py</code> <pre><code>def _calculate_langrange_multiplier(matrix: npt.NDArray, gamma_c: float) -&gt; npt.NDArray:\n    \"\"\"Calculates the Langrange multiplier.\n\n    Args:\n        matrix (npt.NDArray): A matrix. Refer to eq. 22 of [1]\n        gamma_c (float): Differential privacy parameter.\n\n    Returns:\n        npt.NDArray: Langrange multiplier.\n\n    [1] Ravi, Nikhil, Anna Scaglione, and Sean Peisert.\n    \"Colored noise mechanism for differentially private clustering.\" (2021).\n    https://arxiv.org/pdf/2006.03684.pdf\n    \"\"\"\n    lambda_star = np.real(\n        np.power(\n            gamma_c * (np.linalg.inv(matrix) @ np.ones((len(matrix), 1))),\n            -2,\n        )\n    )\n    return lambda_star\n</code></pre>"},{"location":"#cedskmeans._cedskmeans._calculate_objective_function","title":"<code>_calculate_objective_function(matrix, lagrange_multiplier)</code>","text":"<p>Calculates the objective function.</p> <p>Parameters:</p> Name Type Description Default <code>matrix</code> <code>NDArray</code> <p>A matrix. Refer to eq. 13 of [1]</p> required <code>lagrange_multiplier</code> <code>NDArray</code> <p>Langrange multiplier.</p> required <p>Returns:</p> Type Description <code>NDArray</code> <p>npt.NDArray: Objective function.</p> <p>[1] Ravi, Nikhil, Anna Scaglione, and Sean Peisert. \u201cColored noise mechanism for differentially private clustering.\u201d (2021). https://arxiv.org/pdf/2006.03684.pdf</p> Source code in <code>src/cedskmeans/_cedskmeans.py</code> <pre><code>def _calculate_objective_function(\n    matrix: npt.NDArray, lagrange_multiplier: npt.NDArray\n) -&gt; npt.NDArray:\n    \"\"\"Calculates the objective function.\n\n    Args:\n        matrix (npt.NDArray): A matrix. Refer to eq. 13 of [1]\n        lagrange_multiplier (npt.NDArray): Langrange multiplier.\n\n    Returns:\n        npt.NDArray: Objective function.\n\n    [1] Ravi, Nikhil, Anna Scaglione, and Sean Peisert.\n    \"Colored noise mechanism for differentially private clustering.\" (2021).\n    https://arxiv.org/pdf/2006.03684.pdf\n    \"\"\"\n    return np.sum(\n        lagrange_multiplier[i]\n        * np.outer(\n            matrix[:, i],\n            matrix[:, i],\n        )\n        for i in range(matrix.shape[1])\n    )\n</code></pre>"},{"location":"#cedskmeans._cedskmeans._cluster_cardinality","title":"<code>_cluster_cardinality(labels, n_clusters)</code>","text":"<p>Calculates the cardinality of each cluster.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>NDArray</code> <p>Cluster labels for each sample.</p> required <code>n_clusters</code> <code>int</code> <p>Number of clusters.</p> required <p>Returns:</p> Type Description <code>NDArray</code> <p>npt.NDArray: Cardinality of each cluster of shape (n_clusters, 1).</p> Source code in <code>src/cedskmeans/_cedskmeans.py</code> <pre><code>def _cluster_cardinality(labels: npt.NDArray, n_clusters: int) -&gt; npt.NDArray:\n    \"\"\"Calculates the cardinality of each cluster.\n\n    Args:\n        labels (npt.NDArray): Cluster labels for each sample.\n        n_clusters (int): Number of clusters.\n\n    Returns:\n        npt.NDArray: Cardinality of each cluster of shape (n_clusters, 1).\n    \"\"\"\n    return np.bincount(labels, minlength=n_clusters).reshape(-1, 1)\n</code></pre>"},{"location":"#cedskmeans._cedskmeans._cluster_center_without_node","title":"<code>_cluster_center_without_node(X, labels, cluster_sum, cluster_cardinality)</code>","text":"<p>Calculates the cluster center without the data point.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>NDArray</code> <p>Training instances to cluster.</p> required <code>labels</code> <code>NDArray</code> <p>Cluster labels for each sample.</p> required <code>cluster_sum</code> <code>NDArray</code> <p>Sum of data points in each cluster.</p> required <code>cluster_cardinality</code> <code>NDArray</code> <p>Cardinality of each cluster.</p> required <p>Returns:</p> Type Description <code>NDArray</code> <p>npt.NDArray: Cluster center without the data point of shape (n_samples, n_features).</p> Source code in <code>src/cedskmeans/_cedskmeans.py</code> <pre><code>def _cluster_center_without_node(\n    X: npt.NDArray,\n    labels: npt.NDArray,\n    cluster_sum: npt.NDArray,\n    cluster_cardinality: npt.NDArray,\n) -&gt; npt.NDArray:\n    \"\"\"Calculates the cluster center without the data point.\n\n    Args:\n        X (npt.NDArray): Training instances to cluster.\n        labels (npt.NDArray): Cluster labels for each sample.\n        cluster_sum (npt.NDArray): Sum of data points in each cluster.\n        cluster_cardinality (npt.NDArray): Cardinality of each cluster.\n\n    Returns:\n        npt.NDArray: Cluster center without the data point of shape (n_samples, n_features).\n    \"\"\"\n    return (cluster_sum[labels] - X) / (cluster_cardinality[labels] - 1)\n</code></pre>"},{"location":"#cedskmeans._cedskmeans._cluster_sum","title":"<code>_cluster_sum(X, labels, n_clusters)</code>","text":"<p>Calculates the sum of data points in each cluster.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>NDArray</code> <p>Training instances to cluster.</p> required <code>labels</code> <code>NDArray</code> <p>Cluster labels for each sample.</p> required <code>n_clusters</code> <code>int</code> <p>Number of clusters.</p> required <p>Returns:</p> Type Description <code>NDArray</code> <p>npt.NDArray: Sum of data points in each cluster of shape (n_clusters, n_features).</p> Source code in <code>src/cedskmeans/_cedskmeans.py</code> <pre><code>def _cluster_sum(X: npt.NDArray, labels: npt.NDArray, n_clusters: int) -&gt; npt.NDArray:\n    \"\"\"Calculates the sum of data points in each cluster.\n\n    Args:\n        X (npt.NDArray): Training instances to cluster.\n        labels (npt.NDArray): Cluster labels for each sample.\n        n_clusters (int): Number of clusters.\n\n    Returns:\n        npt.NDArray: Sum of data points in each cluster of shape (n_clusters, n_features).\n    \"\"\"\n    return np.array([np.sum(X[labels == k], axis=0) for k in range(n_clusters)])\n</code></pre>"},{"location":"#cedskmeans._cedskmeans._find_independent_columns","title":"<code>_find_independent_columns(matrix)</code>","text":"<p>Finds the independent columns of a matrix.</p> <p>Parameters:</p> Name Type Description Default <code>matrix</code> <code>NDArray</code> <p>Matrix to find independent columns.</p> required <p>Returns:</p> Type Description <code>NDArray</code> <p>npt.NDArray: Independent columns of the matrix.</p> Source code in <code>src/cedskmeans/_cedskmeans.py</code> <pre><code>def _find_independent_columns(matrix: npt.NDArray) -&gt; npt.NDArray:\n    \"\"\"Finds the independent columns of a matrix.\n\n    Args:\n        matrix (npt.NDArray): Matrix to find independent columns.\n\n    Returns:\n        npt.NDArray: Independent columns of the matrix.\n    \"\"\"\n    _, independent_indices = sympy.Matrix(matrix).rref()\n    return matrix[:, independent_indices]\n</code></pre>"},{"location":"#cedskmeans._cedskmeans._modified_cluster_centers","title":"<code>_modified_cluster_centers(X, centers, labels, cluster_center_without_node)</code>","text":"<p>For each data point, this method return a flattened version of the cluster centers with the cluster center of the data point replaced with the cluster center without the data point.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>NDArray</code> <p>Training instances to cluster.</p> required <code>centers</code> <code>NDArray</code> <p>Original cluster centers.</p> required <code>labels</code> <code>NDArray</code> <p>Cluster labels for each sample.</p> required <code>cluster_center_without_node</code> <code>NDArray</code> <p>Cluster center without the data point.</p> required <p>Returns:</p> Type Description <code>NDArray</code> <p>npt.NDArray: Modified cluster centers of shape (n_clusters * n_features, n_samples).</p> Source code in <code>src/cedskmeans/_cedskmeans.py</code> <pre><code>def _modified_cluster_centers(\n    X: npt.NDArray,\n    centers: npt.NDArray,\n    labels: npt.NDArray,\n    cluster_center_without_node: npt.NDArray,\n) -&gt; npt.NDArray:\n    \"\"\"For each data point, this method return a flattened version of the\n    cluster centers with the cluster center of the data point replaced\n    with the cluster center without the data point.\n\n    Args:\n        X (npt.NDArray): Training instances to cluster.\n        centers (npt.NDArray): Original cluster centers.\n        labels (npt.NDArray): Cluster labels for each sample.\n        cluster_center_without_node (npt.NDArray): Cluster center without the data point.\n\n    Returns:\n        npt.NDArray: Modified cluster centers of shape (n_clusters * n_features, n_samples).\n    \"\"\"\n    modified_cluster_centers = np.tile(centers, (X.shape[0], 1, 1))\n    modified_cluster_centers[\n        np.arange(X.shape[0]), labels\n    ] = cluster_center_without_node\n    return modified_cluster_centers.reshape(X.shape[0], -1).T\n</code></pre>"},{"location":"#cedskmeans._cedskmeans._sort_columns_by_norm","title":"<code>_sort_columns_by_norm(matrix)</code>","text":"<p>Sorts the columns of a matrix by their norm.</p> <p>Parameters:</p> Name Type Description Default <code>matrix</code> <code>NDArray</code> <p>Matrix to sort.</p> required <p>Returns:</p> Type Description <code>NDArray</code> <p>npt.NDArray: Sorted matrix.</p> Source code in <code>src/cedskmeans/_cedskmeans.py</code> <pre><code>def _sort_columns_by_norm(matrix: npt.NDArray) -&gt; npt.NDArray:\n    \"\"\"Sorts the columns of a matrix by their norm.\n\n    Args:\n        matrix (npt.NDArray): Matrix to sort.\n\n    Returns:\n        npt.NDArray: Sorted matrix.\n    \"\"\"\n    norm = np.linalg.norm(matrix, axis=0)\n    return matrix[:, np.argsort(norm)]\n</code></pre>"},{"location":"#cedskmeans._cedskmeans._svd_transpose","title":"<code>_svd_transpose(matrix)</code>","text":"<p>Calculates the SVD of the transpose of a matrix.</p> <p>Parameters:</p> Name Type Description Default <code>matrix</code> <code>NDArray</code> <p>Matrix to calculate SVD.</p> required <p>Returns:</p> Type Description <code>NDArray</code> <p>npt.NDArray: SVD of the transpose of the matrix.</p> Source code in <code>src/cedskmeans/_cedskmeans.py</code> <pre><code>def _svd_transpose(matrix: npt.NDArray) -&gt; npt.NDArray:\n    \"\"\"Calculates the SVD of the transpose of a matrix.\n\n    Args:\n        matrix (npt.NDArray): Matrix to calculate SVD.\n\n    Returns:\n        npt.NDArray: SVD of the transpose of the matrix.\n    \"\"\"\n    U, D, V = np.linalg.svd(matrix)\n    return np.square(U[: matrix.shape[1], : matrix.shape[1]] @ np.diag(np.sqrt(D)) @ V)\n</code></pre>"},{"location":"#differentially-private-k-means","title":"Differentially Private K-Means","text":""},{"location":"#cedskmeans._dpkmeans.CEDSKMeans","title":"<code>CEDSKMeans</code>","text":"<p>               Bases: <code>KMeans</code></p> <p>Differentially private k-means clustering.</p> <p>Read more in [1].</p> <p>Parameters:</p> Name Type Description Default <code>n_clusters</code> <code>int</code> <p>Refer to [2]. Defaults to 8.</p> <code>8</code> <code>dp_epsilon</code> <code>float</code> <p>The differential privacy parameter epsilon [1]. Defaults to 0.1.</p> <code>0.1</code> <code>dp_delta</code> <code>float</code> <p>The differential private parameter delta [1]. Defaults to 0.1.</p> <code>0.1</code> <code>init</code> <code>Literal[\"random\", \"k-means++\"</code> <p>Refer to [2]. Defaults to \u201ck-means++\u201d.</p> <code>'k-means++'</code> <code>n_init</code> <code>str | int</code> <p>Refer to [2]. Defaults to \u201cwarn\u201d.</p> <code>'warn'</code> <code>max_iter</code> <code>int</code> <p>Refer to [2]. Defaults to 300.</p> <code>300</code> <code>tol</code> <code>float</code> <p>Refer to [2]. Defaults to 1e-4.</p> <code>0.0001</code> <code>verbose</code> <code>int</code> <p>Refer to [2]. Defaults to 0.</p> <code>0</code> <code>random_state</code> <code>int</code> <p>Refer to [2]. Defaults to None.</p> <code>None</code> <code>copy_x</code> <code>bool</code> <p>Refer to [2]. Defaults to True.</p> <code>True</code> <code>algorithm</code> <code>Literal['lloyd', 'elkan', 'auto', 'full']</code> <p>Refer to [2]. Defaults to \u201clloyd\u201d.</p> <code>'lloyd'</code> Source code in <code>src/cedskmeans/_cedskmeans.py</code> <pre><code>class CEDSKMeans(KMeans):\n    \"\"\"Differentially private k-means clustering.\n\n    Read more in [1].\n\n    Args:\n        n_clusters (int, optional): Refer to [2]. Defaults to 8.\n        dp_epsilon (float, optional): The differential privacy parameter epsilon [1]. Defaults to 0.1.\n        dp_delta (float, optional): The differential private parameter delta [1]. Defaults to 0.1.\n        init (Literal[\"random\", \"k-means++\", optional): Refer to [2]. Defaults to \"k-means++\".\n        n_init (str | int, optional): Refer to [2]. Defaults to \"warn\".\n        max_iter (int, optional): Refer to [2]. Defaults to 300.\n        tol (float, optional): Refer to [2]. Defaults to 1e-4.\n        verbose (int, optional): Refer to [2]. Defaults to 0.\n        random_state (int, optional): Refer to [2]. Defaults to None.\n        copy_x (bool, optional): Refer to [2]. Defaults to True.\n        algorithm (Literal[\"lloyd\", \"elkan\", \"auto\", \"full\"], optional): Refer to [2]. Defaults to \"lloyd\".\n    \"\"\"\n\n    def __init__(\n        self,\n        n_clusters: int = 8,\n        dp_epsilon: float = 0.1,\n        dp_delta: float = 0.1,\n        *,\n        init: Literal[\"random\", \"k-means++\"] = \"k-means++\",\n        n_init: str | int = \"warn\",\n        max_iter: int = 300,\n        tol: float = 1e-4,\n        verbose: int = 0,\n        random_state: int = None,\n        copy_x: bool = True,\n        algorithm: Literal[\"lloyd\", \"elkan\", \"auto\", \"full\"] = \"lloyd\",\n    ):\n        super().__init__(\n            n_clusters=n_clusters,\n            init=init,\n            n_init=n_init,\n            max_iter=max_iter,\n            tol=tol,\n            verbose=verbose,\n            random_state=random_state,\n            copy_x=copy_x,\n            algorithm=algorithm,\n        )\n\n        self.dp_epsilon = dp_epsilon\n        self.dp_delta = dp_delta\n\n    def _add_dp_noise(self, X: npt.NDArray) -&gt; npt.NDArray:\n        \"\"\"Adds differential private noise to the cluster centers.\n\n        Args:\n            X (npt.NDArray): Training instances to cluster  of shape (n_samples, n_features).\n        \"\"\"\n        self.color_cov = self._calculate_color_noise_covariance(X)\n        self.cluster_centers_ = (\n            self.true_cluster_centers_\n            + np.random.multivariate_normal(\n                np.zeros(self.n_clusters * X.shape[1]), self.color_cov\n            ).reshape(self.n_clusters, X.shape[1])\n        )\n        self.labels_ = self.true_labels_\n\n    def _calculate_color_noise_covariance(self, X: npt.NDArray) -&gt; npt.NDArray:\n        \"\"\"Calculates the differentially private color noise covariance matrix [1].\n\n        Args:\n            X (npt.NDArray): Training instances to cluster. Of shape (n_samples, n_features).Training instances to cluster. It must be noted that the data will be converted to C ordering, which will cause a memory copy if the given data is not C-contiguous. If a sparse matrix is passed, a copy will be made if it's not in CSR format.\n\n        Returns:\n            npt.NDArray: DP covariance matrix of shape (n_clusters * n_features, n_clusters * n_features).\n\n        [1] Ravi, Nikhil, Anna Scaglione, and Sean Peisert.\n        \"Colored noise mechanism for differentially private clustering.\" (2021).\n        https://arxiv.org/pdf/2006.03684.pdf\n        \"\"\"\n\n        cluster_cardinality = _cluster_cardinality(self.true_labels_, self.n_clusters)\n        cluster_sum = _cluster_sum(X, self.true_labels_, self.n_clusters)\n        cluster_center_without_node = _cluster_center_without_node(\n            X, self.true_labels_, cluster_sum, cluster_cardinality\n        )\n        modified_cluster_centers = _modified_cluster_centers(\n            X,\n            self.true_cluster_centers_,\n            self.true_labels_,\n            cluster_center_without_node,\n        )\n        change_in_cluster_centers = (\n            self.true_cluster_centers_.reshape(-1, 1) - modified_cluster_centers\n        )  # Form the $\\bm{C}_{XX'}$ matrix\n\n        sorted_change_in_cluster_centers = _sort_columns_by_norm(\n            change_in_cluster_centers\n        )\n        independent_columns = _find_independent_columns(\n            sorted_change_in_cluster_centers\n        )\n        independent_columns_T = _svd_transpose(independent_columns)\n\n        dp_epsilon_total = self.dp_epsilon * self.n_clusters * X.shape[1]\n        gamma_c = dp_epsilon_total**2 / (2 * np.log(2 / self.dp_delta))\n\n        lambda_star = _calculate_langrange_multiplier(independent_columns_T, gamma_c)\n        R_lambda_star = _calculate_objective_function(independent_columns, lambda_star)\n\n        dp_color_covariance = _calculate_color_noise_covariance(R_lambda_star)\n        return dp_color_covariance\n</code></pre>"},{"location":"#cedskmeans._dpkmeans.CEDSKMeans._add_dp_noise","title":"<code>_add_dp_noise(X)</code>","text":"<p>Adds differential private noise to the cluster centers.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>NDArray</code> <p>Training instances to cluster  of shape (n_samples, n_features).</p> required Source code in <code>src/cedskmeans/_cedskmeans.py</code> <pre><code>def _add_dp_noise(self, X: npt.NDArray) -&gt; npt.NDArray:\n    \"\"\"Adds differential private noise to the cluster centers.\n\n    Args:\n        X (npt.NDArray): Training instances to cluster  of shape (n_samples, n_features).\n    \"\"\"\n    self.color_cov = self._calculate_color_noise_covariance(X)\n    self.cluster_centers_ = (\n        self.true_cluster_centers_\n        + np.random.multivariate_normal(\n            np.zeros(self.n_clusters * X.shape[1]), self.color_cov\n        ).reshape(self.n_clusters, X.shape[1])\n    )\n    self.labels_ = self.true_labels_\n</code></pre>"},{"location":"#cedskmeans._dpkmeans.CEDSKMeans._calculate_color_noise_covariance","title":"<code>_calculate_color_noise_covariance(X)</code>","text":"<p>Calculates the differentially private color noise covariance matrix [1].</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>NDArray</code> <p>Training instances to cluster. Of shape (n_samples, n_features).Training instances to cluster. It must be noted that the data will be converted to C ordering, which will cause a memory copy if the given data is not C-contiguous. If a sparse matrix is passed, a copy will be made if it\u2019s not in CSR format.</p> required <p>Returns:</p> Type Description <code>NDArray</code> <p>npt.NDArray: DP covariance matrix of shape (n_clusters * n_features, n_clusters * n_features).</p> <p>[1] Ravi, Nikhil, Anna Scaglione, and Sean Peisert. \u201cColored noise mechanism for differentially private clustering.\u201d (2021). https://arxiv.org/pdf/2006.03684.pdf</p> Source code in <code>src/cedskmeans/_cedskmeans.py</code> <pre><code>def _calculate_color_noise_covariance(self, X: npt.NDArray) -&gt; npt.NDArray:\n    \"\"\"Calculates the differentially private color noise covariance matrix [1].\n\n    Args:\n        X (npt.NDArray): Training instances to cluster. Of shape (n_samples, n_features).Training instances to cluster. It must be noted that the data will be converted to C ordering, which will cause a memory copy if the given data is not C-contiguous. If a sparse matrix is passed, a copy will be made if it's not in CSR format.\n\n    Returns:\n        npt.NDArray: DP covariance matrix of shape (n_clusters * n_features, n_clusters * n_features).\n\n    [1] Ravi, Nikhil, Anna Scaglione, and Sean Peisert.\n    \"Colored noise mechanism for differentially private clustering.\" (2021).\n    https://arxiv.org/pdf/2006.03684.pdf\n    \"\"\"\n\n    cluster_cardinality = _cluster_cardinality(self.true_labels_, self.n_clusters)\n    cluster_sum = _cluster_sum(X, self.true_labels_, self.n_clusters)\n    cluster_center_without_node = _cluster_center_without_node(\n        X, self.true_labels_, cluster_sum, cluster_cardinality\n    )\n    modified_cluster_centers = _modified_cluster_centers(\n        X,\n        self.true_cluster_centers_,\n        self.true_labels_,\n        cluster_center_without_node,\n    )\n    change_in_cluster_centers = (\n        self.true_cluster_centers_.reshape(-1, 1) - modified_cluster_centers\n    )  # Form the $\\bm{C}_{XX'}$ matrix\n\n    sorted_change_in_cluster_centers = _sort_columns_by_norm(\n        change_in_cluster_centers\n    )\n    independent_columns = _find_independent_columns(\n        sorted_change_in_cluster_centers\n    )\n    independent_columns_T = _svd_transpose(independent_columns)\n\n    dp_epsilon_total = self.dp_epsilon * self.n_clusters * X.shape[1]\n    gamma_c = dp_epsilon_total**2 / (2 * np.log(2 / self.dp_delta))\n\n    lambda_star = _calculate_langrange_multiplier(independent_columns_T, gamma_c)\n    R_lambda_star = _calculate_objective_function(independent_columns, lambda_star)\n\n    dp_color_covariance = _calculate_color_noise_covariance(R_lambda_star)\n    return dp_color_covariance\n</code></pre>"},{"location":"#cedskmeans._dpkmeans.DPKMeans","title":"<code>DPKMeans</code>","text":"<p>               Bases: <code>CEDSKMeans</code></p> Source code in <code>src/cedskmeans/_dpkmeans.py</code> <pre><code>class DPKMeans(CEDSKMeans):\n    def fit(\n        self, X: npt.NDArray, y: npt.NDArray = None, sample_weight: npt.ArrayLike = None\n    ):\n        _kmeans_results = super().fit(X=X, y=y, sample_weight=sample_weight)\n        self.true_cluster_centers_ = _kmeans_results.cluster_centers_\n        self._n_features_out = _kmeans_results.cluster_centers_.shape[0]\n        self.true_labels_ = _kmeans_results.labels_\n        self.inertia_ = _kmeans_results.inertia_\n        self.n_iter_ = _kmeans_results.n_iter_\n        self._add_dp_noise(X)\n        return self\n</code></pre>"},{"location":"#map-reduce-k-means-using-ray","title":"Map Reduce K-Means using Ray","text":""},{"location":"#cedskmeans._mapreduce_kmeans.CEDSKMeans","title":"<code>CEDSKMeans</code>","text":"<p>               Bases: <code>KMeans</code></p> <p>Differentially private k-means clustering.</p> <p>Read more in [1].</p> <p>Parameters:</p> Name Type Description Default <code>n_clusters</code> <code>int</code> <p>Refer to [2]. Defaults to 8.</p> <code>8</code> <code>dp_epsilon</code> <code>float</code> <p>The differential privacy parameter epsilon [1]. Defaults to 0.1.</p> <code>0.1</code> <code>dp_delta</code> <code>float</code> <p>The differential private parameter delta [1]. Defaults to 0.1.</p> <code>0.1</code> <code>init</code> <code>Literal[\"random\", \"k-means++\"</code> <p>Refer to [2]. Defaults to \u201ck-means++\u201d.</p> <code>'k-means++'</code> <code>n_init</code> <code>str | int</code> <p>Refer to [2]. Defaults to \u201cwarn\u201d.</p> <code>'warn'</code> <code>max_iter</code> <code>int</code> <p>Refer to [2]. Defaults to 300.</p> <code>300</code> <code>tol</code> <code>float</code> <p>Refer to [2]. Defaults to 1e-4.</p> <code>0.0001</code> <code>verbose</code> <code>int</code> <p>Refer to [2]. Defaults to 0.</p> <code>0</code> <code>random_state</code> <code>int</code> <p>Refer to [2]. Defaults to None.</p> <code>None</code> <code>copy_x</code> <code>bool</code> <p>Refer to [2]. Defaults to True.</p> <code>True</code> <code>algorithm</code> <code>Literal['lloyd', 'elkan', 'auto', 'full']</code> <p>Refer to [2]. Defaults to \u201clloyd\u201d.</p> <code>'lloyd'</code> Source code in <code>src/cedskmeans/_cedskmeans.py</code> <pre><code>class CEDSKMeans(KMeans):\n    \"\"\"Differentially private k-means clustering.\n\n    Read more in [1].\n\n    Args:\n        n_clusters (int, optional): Refer to [2]. Defaults to 8.\n        dp_epsilon (float, optional): The differential privacy parameter epsilon [1]. Defaults to 0.1.\n        dp_delta (float, optional): The differential private parameter delta [1]. Defaults to 0.1.\n        init (Literal[\"random\", \"k-means++\", optional): Refer to [2]. Defaults to \"k-means++\".\n        n_init (str | int, optional): Refer to [2]. Defaults to \"warn\".\n        max_iter (int, optional): Refer to [2]. Defaults to 300.\n        tol (float, optional): Refer to [2]. Defaults to 1e-4.\n        verbose (int, optional): Refer to [2]. Defaults to 0.\n        random_state (int, optional): Refer to [2]. Defaults to None.\n        copy_x (bool, optional): Refer to [2]. Defaults to True.\n        algorithm (Literal[\"lloyd\", \"elkan\", \"auto\", \"full\"], optional): Refer to [2]. Defaults to \"lloyd\".\n    \"\"\"\n\n    def __init__(\n        self,\n        n_clusters: int = 8,\n        dp_epsilon: float = 0.1,\n        dp_delta: float = 0.1,\n        *,\n        init: Literal[\"random\", \"k-means++\"] = \"k-means++\",\n        n_init: str | int = \"warn\",\n        max_iter: int = 300,\n        tol: float = 1e-4,\n        verbose: int = 0,\n        random_state: int = None,\n        copy_x: bool = True,\n        algorithm: Literal[\"lloyd\", \"elkan\", \"auto\", \"full\"] = \"lloyd\",\n    ):\n        super().__init__(\n            n_clusters=n_clusters,\n            init=init,\n            n_init=n_init,\n            max_iter=max_iter,\n            tol=tol,\n            verbose=verbose,\n            random_state=random_state,\n            copy_x=copy_x,\n            algorithm=algorithm,\n        )\n\n        self.dp_epsilon = dp_epsilon\n        self.dp_delta = dp_delta\n\n    def _add_dp_noise(self, X: npt.NDArray) -&gt; npt.NDArray:\n        \"\"\"Adds differential private noise to the cluster centers.\n\n        Args:\n            X (npt.NDArray): Training instances to cluster  of shape (n_samples, n_features).\n        \"\"\"\n        self.color_cov = self._calculate_color_noise_covariance(X)\n        self.cluster_centers_ = (\n            self.true_cluster_centers_\n            + np.random.multivariate_normal(\n                np.zeros(self.n_clusters * X.shape[1]), self.color_cov\n            ).reshape(self.n_clusters, X.shape[1])\n        )\n        self.labels_ = self.true_labels_\n\n    def _calculate_color_noise_covariance(self, X: npt.NDArray) -&gt; npt.NDArray:\n        \"\"\"Calculates the differentially private color noise covariance matrix [1].\n\n        Args:\n            X (npt.NDArray): Training instances to cluster. Of shape (n_samples, n_features).Training instances to cluster. It must be noted that the data will be converted to C ordering, which will cause a memory copy if the given data is not C-contiguous. If a sparse matrix is passed, a copy will be made if it's not in CSR format.\n\n        Returns:\n            npt.NDArray: DP covariance matrix of shape (n_clusters * n_features, n_clusters * n_features).\n\n        [1] Ravi, Nikhil, Anna Scaglione, and Sean Peisert.\n        \"Colored noise mechanism for differentially private clustering.\" (2021).\n        https://arxiv.org/pdf/2006.03684.pdf\n        \"\"\"\n\n        cluster_cardinality = _cluster_cardinality(self.true_labels_, self.n_clusters)\n        cluster_sum = _cluster_sum(X, self.true_labels_, self.n_clusters)\n        cluster_center_without_node = _cluster_center_without_node(\n            X, self.true_labels_, cluster_sum, cluster_cardinality\n        )\n        modified_cluster_centers = _modified_cluster_centers(\n            X,\n            self.true_cluster_centers_,\n            self.true_labels_,\n            cluster_center_without_node,\n        )\n        change_in_cluster_centers = (\n            self.true_cluster_centers_.reshape(-1, 1) - modified_cluster_centers\n        )  # Form the $\\bm{C}_{XX'}$ matrix\n\n        sorted_change_in_cluster_centers = _sort_columns_by_norm(\n            change_in_cluster_centers\n        )\n        independent_columns = _find_independent_columns(\n            sorted_change_in_cluster_centers\n        )\n        independent_columns_T = _svd_transpose(independent_columns)\n\n        dp_epsilon_total = self.dp_epsilon * self.n_clusters * X.shape[1]\n        gamma_c = dp_epsilon_total**2 / (2 * np.log(2 / self.dp_delta))\n\n        lambda_star = _calculate_langrange_multiplier(independent_columns_T, gamma_c)\n        R_lambda_star = _calculate_objective_function(independent_columns, lambda_star)\n\n        dp_color_covariance = _calculate_color_noise_covariance(R_lambda_star)\n        return dp_color_covariance\n</code></pre>"},{"location":"#cedskmeans._mapreduce_kmeans.CEDSKMeans._add_dp_noise","title":"<code>_add_dp_noise(X)</code>","text":"<p>Adds differential private noise to the cluster centers.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>NDArray</code> <p>Training instances to cluster  of shape (n_samples, n_features).</p> required Source code in <code>src/cedskmeans/_cedskmeans.py</code> <pre><code>def _add_dp_noise(self, X: npt.NDArray) -&gt; npt.NDArray:\n    \"\"\"Adds differential private noise to the cluster centers.\n\n    Args:\n        X (npt.NDArray): Training instances to cluster  of shape (n_samples, n_features).\n    \"\"\"\n    self.color_cov = self._calculate_color_noise_covariance(X)\n    self.cluster_centers_ = (\n        self.true_cluster_centers_\n        + np.random.multivariate_normal(\n            np.zeros(self.n_clusters * X.shape[1]), self.color_cov\n        ).reshape(self.n_clusters, X.shape[1])\n    )\n    self.labels_ = self.true_labels_\n</code></pre>"},{"location":"#cedskmeans._mapreduce_kmeans.CEDSKMeans._calculate_color_noise_covariance","title":"<code>_calculate_color_noise_covariance(X)</code>","text":"<p>Calculates the differentially private color noise covariance matrix [1].</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>NDArray</code> <p>Training instances to cluster. Of shape (n_samples, n_features).Training instances to cluster. It must be noted that the data will be converted to C ordering, which will cause a memory copy if the given data is not C-contiguous. If a sparse matrix is passed, a copy will be made if it\u2019s not in CSR format.</p> required <p>Returns:</p> Type Description <code>NDArray</code> <p>npt.NDArray: DP covariance matrix of shape (n_clusters * n_features, n_clusters * n_features).</p> <p>[1] Ravi, Nikhil, Anna Scaglione, and Sean Peisert. \u201cColored noise mechanism for differentially private clustering.\u201d (2021). https://arxiv.org/pdf/2006.03684.pdf</p> Source code in <code>src/cedskmeans/_cedskmeans.py</code> <pre><code>def _calculate_color_noise_covariance(self, X: npt.NDArray) -&gt; npt.NDArray:\n    \"\"\"Calculates the differentially private color noise covariance matrix [1].\n\n    Args:\n        X (npt.NDArray): Training instances to cluster. Of shape (n_samples, n_features).Training instances to cluster. It must be noted that the data will be converted to C ordering, which will cause a memory copy if the given data is not C-contiguous. If a sparse matrix is passed, a copy will be made if it's not in CSR format.\n\n    Returns:\n        npt.NDArray: DP covariance matrix of shape (n_clusters * n_features, n_clusters * n_features).\n\n    [1] Ravi, Nikhil, Anna Scaglione, and Sean Peisert.\n    \"Colored noise mechanism for differentially private clustering.\" (2021).\n    https://arxiv.org/pdf/2006.03684.pdf\n    \"\"\"\n\n    cluster_cardinality = _cluster_cardinality(self.true_labels_, self.n_clusters)\n    cluster_sum = _cluster_sum(X, self.true_labels_, self.n_clusters)\n    cluster_center_without_node = _cluster_center_without_node(\n        X, self.true_labels_, cluster_sum, cluster_cardinality\n    )\n    modified_cluster_centers = _modified_cluster_centers(\n        X,\n        self.true_cluster_centers_,\n        self.true_labels_,\n        cluster_center_without_node,\n    )\n    change_in_cluster_centers = (\n        self.true_cluster_centers_.reshape(-1, 1) - modified_cluster_centers\n    )  # Form the $\\bm{C}_{XX'}$ matrix\n\n    sorted_change_in_cluster_centers = _sort_columns_by_norm(\n        change_in_cluster_centers\n    )\n    independent_columns = _find_independent_columns(\n        sorted_change_in_cluster_centers\n    )\n    independent_columns_T = _svd_transpose(independent_columns)\n\n    dp_epsilon_total = self.dp_epsilon * self.n_clusters * X.shape[1]\n    gamma_c = dp_epsilon_total**2 / (2 * np.log(2 / self.dp_delta))\n\n    lambda_star = _calculate_langrange_multiplier(independent_columns_T, gamma_c)\n    R_lambda_star = _calculate_objective_function(independent_columns, lambda_star)\n\n    dp_color_covariance = _calculate_color_noise_covariance(R_lambda_star)\n    return dp_color_covariance\n</code></pre>"},{"location":"#cedskmeans._mapreduce_kmeans.KMeansMap","title":"<code>KMeansMap</code>","text":"<p>A remote Ray class for performing K-means clustering map tasks.</p> <p>Parameters:</p> Name Type Description Default <code>items</code> <code>ndarray</code> <p>The input array of items.</p> required <code>num_clusters</code> <code>int</code> <p>The number of clusters (default: 1).</p> <code>1</code> <p>Attributes:</p> Name Type Description <code>items</code> <code>ndarray</code> <p>The input array of items.</p> <code>num_clusters</code> <code>int</code> <p>The number of clusters.</p> <code>cluster_assignments</code> <code>ndarray</code> <p>The array to store cluster assignments.</p> <code>distances_matrix</code> <code>ndarray</code> <p>The matrix containing pre-calculated distances between centroids.</p> Source code in <code>src/cedskmeans/_map_reduce/_mapper.py</code> <pre><code>@ray.remote(num_cpus=1)\nclass KMeansMap:\n    \"\"\"\n    A remote Ray class for performing K-means clustering map tasks.\n\n    Args:\n        items (np.ndarray): The input array of items.\n        num_clusters (int, optional): The number of clusters (default: 1).\n\n    Attributes:\n        items (np.ndarray): The input array of items.\n        num_clusters (int): The number of clusters.\n        cluster_assignments (np.ndarray): The array to store cluster assignments.\n        distances_matrix (np.ndarray): The matrix containing pre-calculated distances between centroids.\n    \"\"\"\n\n    centroids = 0\n\n    def __init__(self, items: np.ndarray, num_clusters: int = 1):\n        self.items = items\n        self.num_clusters = num_clusters\n        self.cluster_assignments = None\n        self.centroids = None\n        self.distances_matrix = None\n\n    def communicate_centroids(self, centroids: np.ndarray):\n        \"\"\"\n        Communicates the centroids to the KMeansMap instance.\n\n        Args:\n            centroids (np.ndarray): The centroids to be communicated.\n        \"\"\"\n        self.centroids = centroids\n\n    def communicate_distances(self, distances_matrix: np.ndarray):\n        \"\"\"\n        Communicates the distances matrix to the KMeansMap instance.\n\n        Args:\n            distances_matrix (np.ndarray): The distances matrix to be communicated.\n        \"\"\"\n        self.distances_matrix = distances_matrix\n\n    @staticmethod\n    def calculate_distance(point_a: np.ndarray, point_b: np.ndarray) -&gt; float:\n        \"\"\"\n        Calculates the distance between two points.\n\n        Args:\n            point_a (np.ndarray): The first point.\n            point_b (np.ndarray): The second point.\n\n        Returns:\n            float: The distance between the two points.\n        \"\"\"\n        return np.linalg.norm(point_a - point_b)\n\n    def read_cluster_assignments(self) -&gt; np.ndarray:\n        \"\"\"\n        Reads the cluster assignments.\n\n        Returns:\n            np.ndarray: The cluster assignments.\n        \"\"\"\n        return self.cluster_assignments\n\n    def read_items(self) -&gt; np.ndarray:\n        \"\"\"\n        Reads the input array of items.\n\n        Returns:\n            np.ndarray: The input array of items\n        \"\"\"\n        return self.items\n\n    def assign_clusters(self) -&gt; np.ndarray:\n        \"\"\"\n        Assigns clusters to each item.\n\n        Returns:\n            np.ndarray: The cluster assignments.\n        \"\"\"\n        num_items = self.items.shape[0]\n        self.cluster_assignments = np.zeros((num_items, 2))\n\n        for i in range(num_items):\n            min_index, min_distance = KMeansMap.find_closest_centroid(\n                self.num_clusters, self.centroids, self.items, i, self.distances_matrix\n            )\n            self.cluster_assignments[i, :] = min_index, min_distance\n\n        return self.cluster_assignments\n\n    @staticmethod\n    def find_closest_centroid(\n        num_clusters: int,\n        centroids: np.ndarray,\n        items: np.ndarray,\n        item_index: int,\n        distances_matrix: np.ndarray,\n    ) -&gt; tuple[int, float]:\n        \"\"\"\n        Find the index of the closest centroid to the given item.\n\n        Args:\n            num_clusters (int): The number of centroids.\n            centroids (np.ndarray): An array of centroid coordinates.\n            items (np.ndarray): An array of item coordinates.\n            item_index (int): Index of the item to compare.\n            distances_matrix (np.ndarray): Matrix containing pre-calculated distances between centroids.\n\n        Returns:\n            tuple[int, float]: Index of the closest centroid and the corresponding distance.\n        \"\"\"\n        best_distance = np.inf\n        best_index = -1\n        j = 0\n        num_centroids = centroids.shape[0]\n\n        while j &lt; num_centroids:\n            center = centroids[j]\n            distance = np.linalg.norm(center - items[item_index])\n\n            if distance &lt; best_distance:\n                best_distance = distance\n                best_index = j\n\n            if j &lt;= num_clusters - 2 and 2 * distance &lt;= distances_matrix[j, j + 1]:\n                j += 1\n\n            j += 1\n\n        return best_index, best_distance\n</code></pre>"},{"location":"#cedskmeans._mapreduce_kmeans.KMeansMap.assign_clusters","title":"<code>assign_clusters()</code>","text":"<p>Assigns clusters to each item.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The cluster assignments.</p> Source code in <code>src/cedskmeans/_map_reduce/_mapper.py</code> <pre><code>def assign_clusters(self) -&gt; np.ndarray:\n    \"\"\"\n    Assigns clusters to each item.\n\n    Returns:\n        np.ndarray: The cluster assignments.\n    \"\"\"\n    num_items = self.items.shape[0]\n    self.cluster_assignments = np.zeros((num_items, 2))\n\n    for i in range(num_items):\n        min_index, min_distance = KMeansMap.find_closest_centroid(\n            self.num_clusters, self.centroids, self.items, i, self.distances_matrix\n        )\n        self.cluster_assignments[i, :] = min_index, min_distance\n\n    return self.cluster_assignments\n</code></pre>"},{"location":"#cedskmeans._mapreduce_kmeans.KMeansMap.calculate_distance","title":"<code>calculate_distance(point_a, point_b)</code>  <code>staticmethod</code>","text":"<p>Calculates the distance between two points.</p> <p>Parameters:</p> Name Type Description Default <code>point_a</code> <code>ndarray</code> <p>The first point.</p> required <code>point_b</code> <code>ndarray</code> <p>The second point.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The distance between the two points.</p> Source code in <code>src/cedskmeans/_map_reduce/_mapper.py</code> <pre><code>@staticmethod\ndef calculate_distance(point_a: np.ndarray, point_b: np.ndarray) -&gt; float:\n    \"\"\"\n    Calculates the distance between two points.\n\n    Args:\n        point_a (np.ndarray): The first point.\n        point_b (np.ndarray): The second point.\n\n    Returns:\n        float: The distance between the two points.\n    \"\"\"\n    return np.linalg.norm(point_a - point_b)\n</code></pre>"},{"location":"#cedskmeans._mapreduce_kmeans.KMeansMap.communicate_centroids","title":"<code>communicate_centroids(centroids)</code>","text":"<p>Communicates the centroids to the KMeansMap instance.</p> <p>Parameters:</p> Name Type Description Default <code>centroids</code> <code>ndarray</code> <p>The centroids to be communicated.</p> required Source code in <code>src/cedskmeans/_map_reduce/_mapper.py</code> <pre><code>def communicate_centroids(self, centroids: np.ndarray):\n    \"\"\"\n    Communicates the centroids to the KMeansMap instance.\n\n    Args:\n        centroids (np.ndarray): The centroids to be communicated.\n    \"\"\"\n    self.centroids = centroids\n</code></pre>"},{"location":"#cedskmeans._mapreduce_kmeans.KMeansMap.communicate_distances","title":"<code>communicate_distances(distances_matrix)</code>","text":"<p>Communicates the distances matrix to the KMeansMap instance.</p> <p>Parameters:</p> Name Type Description Default <code>distances_matrix</code> <code>ndarray</code> <p>The distances matrix to be communicated.</p> required Source code in <code>src/cedskmeans/_map_reduce/_mapper.py</code> <pre><code>def communicate_distances(self, distances_matrix: np.ndarray):\n    \"\"\"\n    Communicates the distances matrix to the KMeansMap instance.\n\n    Args:\n        distances_matrix (np.ndarray): The distances matrix to be communicated.\n    \"\"\"\n    self.distances_matrix = distances_matrix\n</code></pre>"},{"location":"#cedskmeans._mapreduce_kmeans.KMeansMap.find_closest_centroid","title":"<code>find_closest_centroid(num_clusters, centroids, items, item_index, distances_matrix)</code>  <code>staticmethod</code>","text":"<p>Find the index of the closest centroid to the given item.</p> <p>Parameters:</p> Name Type Description Default <code>num_clusters</code> <code>int</code> <p>The number of centroids.</p> required <code>centroids</code> <code>ndarray</code> <p>An array of centroid coordinates.</p> required <code>items</code> <code>ndarray</code> <p>An array of item coordinates.</p> required <code>item_index</code> <code>int</code> <p>Index of the item to compare.</p> required <code>distances_matrix</code> <code>ndarray</code> <p>Matrix containing pre-calculated distances between centroids.</p> required <p>Returns:</p> Type Description <code>tuple[int, float]</code> <p>tuple[int, float]: Index of the closest centroid and the corresponding distance.</p> Source code in <code>src/cedskmeans/_map_reduce/_mapper.py</code> <pre><code>@staticmethod\ndef find_closest_centroid(\n    num_clusters: int,\n    centroids: np.ndarray,\n    items: np.ndarray,\n    item_index: int,\n    distances_matrix: np.ndarray,\n) -&gt; tuple[int, float]:\n    \"\"\"\n    Find the index of the closest centroid to the given item.\n\n    Args:\n        num_clusters (int): The number of centroids.\n        centroids (np.ndarray): An array of centroid coordinates.\n        items (np.ndarray): An array of item coordinates.\n        item_index (int): Index of the item to compare.\n        distances_matrix (np.ndarray): Matrix containing pre-calculated distances between centroids.\n\n    Returns:\n        tuple[int, float]: Index of the closest centroid and the corresponding distance.\n    \"\"\"\n    best_distance = np.inf\n    best_index = -1\n    j = 0\n    num_centroids = centroids.shape[0]\n\n    while j &lt; num_centroids:\n        center = centroids[j]\n        distance = np.linalg.norm(center - items[item_index])\n\n        if distance &lt; best_distance:\n            best_distance = distance\n            best_index = j\n\n        if j &lt;= num_clusters - 2 and 2 * distance &lt;= distances_matrix[j, j + 1]:\n            j += 1\n\n        j += 1\n\n    return best_index, best_distance\n</code></pre>"},{"location":"#cedskmeans._mapreduce_kmeans.KMeansMap.read_cluster_assignments","title":"<code>read_cluster_assignments()</code>","text":"<p>Reads the cluster assignments.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The cluster assignments.</p> Source code in <code>src/cedskmeans/_map_reduce/_mapper.py</code> <pre><code>def read_cluster_assignments(self) -&gt; np.ndarray:\n    \"\"\"\n    Reads the cluster assignments.\n\n    Returns:\n        np.ndarray: The cluster assignments.\n    \"\"\"\n    return self.cluster_assignments\n</code></pre>"},{"location":"#cedskmeans._mapreduce_kmeans.KMeansMap.read_items","title":"<code>read_items()</code>","text":"<p>Reads the input array of items.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The input array of items</p> Source code in <code>src/cedskmeans/_map_reduce/_mapper.py</code> <pre><code>def read_items(self) -&gt; np.ndarray:\n    \"\"\"\n    Reads the input array of items.\n\n    Returns:\n        np.ndarray: The input array of items\n    \"\"\"\n    return self.items\n</code></pre>"},{"location":"#cedskmeans._mapreduce_kmeans.KMeansMapReduce","title":"<code>KMeansMapReduce</code>","text":"<p>               Bases: <code>CEDSKMeans</code></p> <p>K-means clustering using MapReduce.</p> Source code in <code>src/cedskmeans/_mapreduce_kmeans.py</code> <pre><code>class KMeansMapReduce(CEDSKMeans):\n    \"\"\"\n    K-means clustering using MapReduce.\n    \"\"\"\n\n    def __init__(\n        self,\n        n_clusters: int = 20,\n        dp_epsilon: float = 0.1,\n        dp_delta: float = 0.1,\n        n_mappers: int = 5,\n        *,\n        init: Literal[\"random\", \"k-means++\"] = \"k-means++\",\n        n_init: str | int = \"warn\",\n        max_iter: int = 10,\n        tol: float = 1e-4,\n        verbose: int = 0,\n        random_state: int = None,  # type: ignore\n        copy_x: bool = True,\n        algorithm: Literal[\"lloyd\", \"elkan\", \"auto\", \"full\"] = \"lloyd\",\n    ) -&gt; None:\n        super().__init__(\n            n_clusters=n_clusters,\n            init=init,\n            n_init=n_init,\n            max_iter=max_iter,\n            tol=tol,\n            verbose=verbose,\n            random_state=random_state,\n            copy_x=copy_x,\n            algorithm=algorithm,\n            dp_epsilon=dp_epsilon,\n            dp_delta=dp_delta,\n        )\n        self.n_mappers = n_mappers\n        self.true_cluster_centers_ = None\n        self.cluster_centers_ = None\n        self.cost = None\n\n    def fit(self, X: pd.DataFrame, y: npt.ArrayLike = None):\n        \"\"\"Compute k-means clustering.\n\n        Args:\n            X (npt.NDArray): Training instances to cluster  of shape (n_samples, n_features). It must be noted that the data will be converted to C ordering, which will cause a memory copy if the given data is not C-contiguous. If a sparse matrix is passed, a copy will be made if it's not in CSR format.\n            y (npt.NDArray): Ignored. Not used, present here for API consistency by convention.\n            sample_weight (npt.ArrayLike): The weights for each observation in X. If None, all observations are assigned equal weight. Defaults to None.\n\n        Returns:\n            self (object): Fitted estimator.\n        \"\"\"\n        self.n_features_out = X.shape[1]\n        batches = split_data(X, num_splits=self.n_mappers)\n        center = initialize_clusters(X.values, self.n_clusters)\n        distance_matrix = calculate_distance_matrix(center)\n\n        mappers = [\n            KMeansMap.remote(mini_batch.values, num_clusters=self.n_clusters)\n            for mini_batch in batches\n        ]\n        reducers = [\n            KMeansReduce.remote(i, self.n_features_out, *mappers)\n            for i in range(self.n_clusters)\n        ]\n\n        cost = np.empty((self.max_iter, 1))\n        for i in range(self.max_iter):\n            ray.get(\n                [mapper.communicate_centroids.remote(center) for mapper in mappers]\n                + [\n                    mapper.communicate_distances.remote(distance_matrix)\n                    for mapper in mappers\n                ]\n            )\n            ray.get([mapper.assign_clusters.remote() for mapper in mappers])\n\n            new_center, cost[i] = create_new_cluster(reducers)\n            changed, _ = has_cluster_changed(new_center, center)\n            if not changed:\n                break\n            else:\n                center = new_center\n                distance_matrix = calculate_distance_matrix(center)\n        self.cost = cost[-1]\n        self.n_iter_ = i\n        self.true_cluster_centers_ = center\n        self._n_features_out = center.shape[0]\n        self.true_labels_ = self.predict(X)\n        self.n_iter_ = i\n        self.cluster_centers_ = center\n        self._add_dp_noise(X)\n        return self\n\n    def predict(self, X: pd.DataFrame, dp: bool = False) -&gt; np.ndarray:\n        \"\"\"\n        Predict the closest cluster each sample in X belongs to.\n\n        Args:\n            X (pd.DataFrame): New data to predict.\n\n        Returns:\n            np.ndarray: Index of the cluster each sample belongs to.\n        \"\"\"\n        if dp:\n            if self.cluster_centers_ is None:\n                raise ValueError(\n                    \"The model has not been trained yet. Please call 'fit' first.\"\n                )\n            center = self.cluster_centers_\n        else:\n            if self.true_cluster_centers_ is None:\n                raise ValueError(\n                    \"The model has not been trained yet. Please call 'fit' first.\"\n                )\n            center = self.true_cluster_centers_\n        if isinstance(X, pd.DataFrame):\n            X = X.values\n        distances = np.array([euclidean_distance(x, c) for x in X for c in center])\n        distances = distances.reshape(X.shape[0], self.n_clusters)\n        return np.argmin(distances, axis=1)\n</code></pre>"},{"location":"#cedskmeans._mapreduce_kmeans.KMeansMapReduce.fit","title":"<code>fit(X, y=None)</code>","text":"<p>Compute k-means clustering.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>NDArray</code> <p>Training instances to cluster  of shape (n_samples, n_features). It must be noted that the data will be converted to C ordering, which will cause a memory copy if the given data is not C-contiguous. If a sparse matrix is passed, a copy will be made if it\u2019s not in CSR format.</p> required <code>y</code> <code>NDArray</code> <p>Ignored. Not used, present here for API consistency by convention.</p> <code>None</code> <code>sample_weight</code> <code>ArrayLike</code> <p>The weights for each observation in X. If None, all observations are assigned equal weight. Defaults to None.</p> required <p>Returns:</p> Name Type Description <code>self</code> <code>object</code> <p>Fitted estimator.</p> Source code in <code>src/cedskmeans/_mapreduce_kmeans.py</code> <pre><code>def fit(self, X: pd.DataFrame, y: npt.ArrayLike = None):\n    \"\"\"Compute k-means clustering.\n\n    Args:\n        X (npt.NDArray): Training instances to cluster  of shape (n_samples, n_features). It must be noted that the data will be converted to C ordering, which will cause a memory copy if the given data is not C-contiguous. If a sparse matrix is passed, a copy will be made if it's not in CSR format.\n        y (npt.NDArray): Ignored. Not used, present here for API consistency by convention.\n        sample_weight (npt.ArrayLike): The weights for each observation in X. If None, all observations are assigned equal weight. Defaults to None.\n\n    Returns:\n        self (object): Fitted estimator.\n    \"\"\"\n    self.n_features_out = X.shape[1]\n    batches = split_data(X, num_splits=self.n_mappers)\n    center = initialize_clusters(X.values, self.n_clusters)\n    distance_matrix = calculate_distance_matrix(center)\n\n    mappers = [\n        KMeansMap.remote(mini_batch.values, num_clusters=self.n_clusters)\n        for mini_batch in batches\n    ]\n    reducers = [\n        KMeansReduce.remote(i, self.n_features_out, *mappers)\n        for i in range(self.n_clusters)\n    ]\n\n    cost = np.empty((self.max_iter, 1))\n    for i in range(self.max_iter):\n        ray.get(\n            [mapper.communicate_centroids.remote(center) for mapper in mappers]\n            + [\n                mapper.communicate_distances.remote(distance_matrix)\n                for mapper in mappers\n            ]\n        )\n        ray.get([mapper.assign_clusters.remote() for mapper in mappers])\n\n        new_center, cost[i] = create_new_cluster(reducers)\n        changed, _ = has_cluster_changed(new_center, center)\n        if not changed:\n            break\n        else:\n            center = new_center\n            distance_matrix = calculate_distance_matrix(center)\n    self.cost = cost[-1]\n    self.n_iter_ = i\n    self.true_cluster_centers_ = center\n    self._n_features_out = center.shape[0]\n    self.true_labels_ = self.predict(X)\n    self.n_iter_ = i\n    self.cluster_centers_ = center\n    self._add_dp_noise(X)\n    return self\n</code></pre>"},{"location":"#cedskmeans._mapreduce_kmeans.KMeansMapReduce.predict","title":"<code>predict(X, dp=False)</code>","text":"<p>Predict the closest cluster each sample in X belongs to.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>DataFrame</code> <p>New data to predict.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Index of the cluster each sample belongs to.</p> Source code in <code>src/cedskmeans/_mapreduce_kmeans.py</code> <pre><code>def predict(self, X: pd.DataFrame, dp: bool = False) -&gt; np.ndarray:\n    \"\"\"\n    Predict the closest cluster each sample in X belongs to.\n\n    Args:\n        X (pd.DataFrame): New data to predict.\n\n    Returns:\n        np.ndarray: Index of the cluster each sample belongs to.\n    \"\"\"\n    if dp:\n        if self.cluster_centers_ is None:\n            raise ValueError(\n                \"The model has not been trained yet. Please call 'fit' first.\"\n            )\n        center = self.cluster_centers_\n    else:\n        if self.true_cluster_centers_ is None:\n            raise ValueError(\n                \"The model has not been trained yet. Please call 'fit' first.\"\n            )\n        center = self.true_cluster_centers_\n    if isinstance(X, pd.DataFrame):\n        X = X.values\n    distances = np.array([euclidean_distance(x, c) for x in X for c in center])\n    distances = distances.reshape(X.shape[0], self.n_clusters)\n    return np.argmin(distances, axis=1)\n</code></pre>"},{"location":"#cedskmeans._mapreduce_kmeans.KMeansReduce","title":"<code>KMeansReduce</code>","text":"<p>Class representing a K-Means reducer.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>int</code> <p>The value associated with the reducer.</p> required <code>n_features</code> <code>int</code> <p>The number of features in the data.</p> required <code>*kmeans_maps</code> <code>list[ActorHandle]</code> <p>Variable-length arguments representing K-Means mappers.</p> <code>()</code> <p>Attributes:</p> Name Type Description <code>value</code> <code>int</code> <p>The value associated with the reducer.</p> <code>kmeans_maps</code> <code>list[ActorHandle]</code> <p>List of K-Means mapper handles.</p> <code>centroid</code> <code>None | ndarray</code> <p>The computed centroid of the cluster.</p> <code>cluster_output</code> <code>ndarray</code> <p>The combined cluster output.</p> <code>cost</code> <code>float</code> <p>The cost of the clustering.</p> Source code in <code>src/cedskmeans/_map_reduce/_reducer.py</code> <pre><code>@ray.remote(num_cpus=1)\nclass KMeansReduce:\n    \"\"\"\n    Class representing a K-Means reducer.\n\n    Args:\n        value (int): The value associated with the reducer.\n        n_features (int): The number of features in the data.\n        *kmeans_maps (list[ray.actor.ActorHandle]): Variable-length arguments representing K-Means mappers.\n\n    Attributes:\n        value (int): The value associated with the reducer.\n        kmeans_maps (list[ray.actor.ActorHandle]): List of K-Means mapper handles.\n        centroid (None | np.ndarray): The computed centroid of the cluster.\n        cluster_output (np.ndarray): The combined cluster output.\n        cost (float): The cost of the clustering.\n    \"\"\"\n\n    def __init__(\n        self, value: int, n_features: int, *kmeans_maps: ray.actor.ActorHandle\n    ) -&gt; None:\n        self.value = value\n        self.kmeans_maps = kmeans_maps\n        self.centroid = None\n        self.cluster_output = np.zeros((1, n_features))\n        self.cost = 0\n\n    def read(self) -&gt; int:\n        \"\"\"\n        Get the value associated with the reducer.\n\n        Returns:\n            int: The value associated with the reducer.\n        \"\"\"\n        return self.value\n\n    def read_cost(self) -&gt; float:\n        \"\"\"\n        Get the cost of the clustering.\n\n        Returns:\n            float: The cost of the clustering.\n        \"\"\"\n        return self.cost\n\n    def update_cluster(self) -&gt; None | np.ndarray:\n        \"\"\"\n        Update the cluster by computing the centroid. This method collects all the\n        references to the cluster assignments and mapper items before calling ray.get().\n\n        Returns:\n            None | np.ndarray: The computed centroid, or None if an error occurs.\n        \"\"\"\n        cluster_assignment_refs = [\n            kmeans_map.assign_clusters.remote() for kmeans_map in self.kmeans_maps\n        ]\n        mapper_items_refs = [\n            kmeans_map.read_items.remote() for kmeans_map in self.kmeans_maps\n        ]\n\n        cluster_assignments = ray.get(cluster_assignment_refs)\n\n        self.cost = np.sum(\n            [\n                np.sum(cluster_assignment[:, 1])\n                for cluster_assignment in cluster_assignments\n            ]\n        )\n        cluster_indices_all = [\n            np.where(cluster_assignment[:, 0] == self.value)[0]\n            for cluster_assignment in cluster_assignments\n        ]\n        mapper_items_all = ray.get(mapper_items_refs)\n        self.cluster_output = np.concatenate(\n            [\n                mapper_items[cluster_indices]\n                for mapper_items, cluster_indices, in zip(\n                    mapper_items_all, cluster_indices_all\n                )\n            ]\n        )\n        self.centroid = np.mean(self.cluster_output, axis=0)\n        return self.centroid\n</code></pre>"},{"location":"#cedskmeans._mapreduce_kmeans.KMeansReduce.read","title":"<code>read()</code>","text":"<p>Get the value associated with the reducer.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The value associated with the reducer.</p> Source code in <code>src/cedskmeans/_map_reduce/_reducer.py</code> <pre><code>def read(self) -&gt; int:\n    \"\"\"\n    Get the value associated with the reducer.\n\n    Returns:\n        int: The value associated with the reducer.\n    \"\"\"\n    return self.value\n</code></pre>"},{"location":"#cedskmeans._mapreduce_kmeans.KMeansReduce.read_cost","title":"<code>read_cost()</code>","text":"<p>Get the cost of the clustering.</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The cost of the clustering.</p> Source code in <code>src/cedskmeans/_map_reduce/_reducer.py</code> <pre><code>def read_cost(self) -&gt; float:\n    \"\"\"\n    Get the cost of the clustering.\n\n    Returns:\n        float: The cost of the clustering.\n    \"\"\"\n    return self.cost\n</code></pre>"},{"location":"#cedskmeans._mapreduce_kmeans.KMeansReduce.update_cluster","title":"<code>update_cluster()</code>","text":"<p>Update the cluster by computing the centroid. This method collects all the references to the cluster assignments and mapper items before calling ray.get().</p> <p>Returns:</p> Type Description <code>None | ndarray</code> <p>None | np.ndarray: The computed centroid, or None if an error occurs.</p> Source code in <code>src/cedskmeans/_map_reduce/_reducer.py</code> <pre><code>def update_cluster(self) -&gt; None | np.ndarray:\n    \"\"\"\n    Update the cluster by computing the centroid. This method collects all the\n    references to the cluster assignments and mapper items before calling ray.get().\n\n    Returns:\n        None | np.ndarray: The computed centroid, or None if an error occurs.\n    \"\"\"\n    cluster_assignment_refs = [\n        kmeans_map.assign_clusters.remote() for kmeans_map in self.kmeans_maps\n    ]\n    mapper_items_refs = [\n        kmeans_map.read_items.remote() for kmeans_map in self.kmeans_maps\n    ]\n\n    cluster_assignments = ray.get(cluster_assignment_refs)\n\n    self.cost = np.sum(\n        [\n            np.sum(cluster_assignment[:, 1])\n            for cluster_assignment in cluster_assignments\n        ]\n    )\n    cluster_indices_all = [\n        np.where(cluster_assignment[:, 0] == self.value)[0]\n        for cluster_assignment in cluster_assignments\n    ]\n    mapper_items_all = ray.get(mapper_items_refs)\n    self.cluster_output = np.concatenate(\n        [\n            mapper_items[cluster_indices]\n            for mapper_items, cluster_indices, in zip(\n                mapper_items_all, cluster_indices_all\n            )\n        ]\n    )\n    self.centroid = np.mean(self.cluster_output, axis=0)\n    return self.centroid\n</code></pre>"},{"location":"#cedskmeans._mapreduce_kmeans.calculate_distance_matrix","title":"<code>calculate_distance_matrix(center)</code>","text":"<p>Calculate the distance matrix between points in the given center array.</p> <p>Parameters:</p> Name Type Description Default <code>center</code> <code>ndarray</code> <p>Array of points representing the center.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The distance matrix between points in the center array.</p> Source code in <code>src/cedskmeans/_map_reduce/_utils.py</code> <pre><code>def calculate_distance_matrix(center: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Calculate the distance matrix between points in the given center array.\n\n    Args:\n        center (np.ndarray): Array of points representing the center.\n\n    Returns:\n        np.ndarray: The distance matrix between points in the center array.\n\n    \"\"\"\n    n = center.shape[0]\n    distance_matrix = np.empty((n, n))\n    for i in range(n - 1):\n        distance_matrix[i, i + 1] = np.linalg.norm(center[i + 1, :] - center[i, :])\n    return distance_matrix\n</code></pre>"},{"location":"#cedskmeans._mapreduce_kmeans.create_new_cluster","title":"<code>create_new_cluster(reducers)</code>","text":"<p>Creates a new cluster by combining clusters from multiple KMeansReduce objects.</p> <p>Parameters:</p> Name Type Description Default <code>reducers</code> <code>list[KMeansReduce]</code> <p>A list of KMeansReduce objects.</p> required <code>n_features</code> <p>The number of features in the dataset.</p> required <p>Returns:</p> Type Description <code>tuple[ndarray, float]</code> <p>A tuple containing the new cluster as a NumPy array and the total cost.</p> Source code in <code>src/cedskmeans/_map_reduce/_utils.py</code> <pre><code>def create_new_cluster(reducers: list[KMeansReduce]) -&gt; tuple[np.ndarray, float]:\n    \"\"\"\n    Creates a new cluster by combining clusters from multiple KMeansReduce objects.\n\n    Args:\n        reducers: A list of KMeansReduce objects.\n        n_features: The number of features in the dataset.\n\n    Returns:\n        A tuple containing the new cluster as a NumPy array and the total cost.\n\n    \"\"\"\n    cluster_refs = []\n    cost_refs = []\n    for reducer in reducers:\n        cluster_refs.append(reducer.update_cluster.remote())\n        cost_refs.append(reducer.read_cost.remote())\n    # TODO: In the KMeansReduce class, the update_cluster method should be first\n    # called and only at its conclusion should the read_cost method be called.\n    # So, should the cost_refs be gathered after ray.get(cluster_refs)?\n    combined_cluster = ray.get(cluster_refs)\n    total_cost = ray.get(cost_refs)\n    return np.array(combined_cluster), np.sum(total_cost)\n</code></pre>"},{"location":"#cedskmeans._mapreduce_kmeans.euclidean_distance","title":"<code>euclidean_distance(point1, point2)</code>","text":"<p>Calculate the Euclidean distance between two points.</p> <p>Parameters:</p> Name Type Description Default <code>point1</code> <code>ndarray</code> <p>First point.</p> required <code>point2</code> <code>ndarray</code> <p>Second point.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The Euclidean distance between the two points.</p> Source code in <code>src/cedskmeans/_mapreduce_kmeans.py</code> <pre><code>def euclidean_distance(point1: np.ndarray, point2: np.ndarray) -&gt; float:\n    \"\"\"\n    Calculate the Euclidean distance between two points.\n\n    Args:\n        point1 (np.ndarray): First point.\n        point2 (np.ndarray): Second point.\n\n    Returns:\n        float: The Euclidean distance between the two points.\n    \"\"\"\n    return np.sqrt(np.sum((point1 - point2) ** 2))\n</code></pre>"},{"location":"#cedskmeans._mapreduce_kmeans.has_cluster_changed","title":"<code>has_cluster_changed(new_centers, old_centers, epsilon=0.0001)</code>","text":"<p>Checks if the cluster centers have changed based on a given epsilon threshold.</p> <p>Parameters:</p> Name Type Description Default <code>new_centers</code> <code>ndarray</code> <p>The new cluster centers as a NumPy array.</p> required <code>old_centers</code> <code>ndarray</code> <p>The old cluster centers as a NumPy array.</p> required <code>epsilon</code> <code>float</code> <p>The threshold value for considering a change (default: 1e-4).</p> <code>0.0001</code> <p>Returns:</p> Type Description <code>tuple[bool, float]</code> <p>A tuple containing a boolean flag indicating if the clusters have changed and the total cost.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the dimensions of new_centers and old_centers do not match.</p> Source code in <code>src/cedskmeans/_map_reduce/_utils.py</code> <pre><code>def has_cluster_changed(\n    new_centers: np.ndarray, old_centers: np.ndarray, epsilon: float = 1e-4\n) -&gt; tuple[bool, float]:\n    \"\"\"\n    Checks if the cluster centers have changed based on a given epsilon threshold.\n\n    Args:\n        new_centers: The new cluster centers as a NumPy array.\n        old_centers: The old cluster centers as a NumPy array.\n        epsilon: The threshold value for considering a change (default: 1e-4).\n\n    Returns:\n        A tuple containing a boolean flag indicating if the clusters have changed and the total cost.\n\n    Raises:\n        ValueError: If the dimensions of new_centers and old_centers do not match.\n\n    \"\"\"\n    if new_centers.shape[0] != old_centers.shape[0]:\n        raise ValueError(\n            \"Error: Dimensions of new_centers and old_centers do not match!\"\n        )\n\n    n = new_centers.shape[0]\n    total_cost = 0.0\n    changed = False\n\n    for i in range(n):\n        squared_diff = fast_squared_distance(new_centers[i], old_centers[i])\n        if squared_diff &gt; epsilon**2:\n            changed = True\n        total_cost += squared_diff\n\n    return changed, total_cost\n</code></pre>"},{"location":"#cedskmeans._mapreduce_kmeans.initialize_clusters","title":"<code>initialize_clusters(data, n_clusters, random_state=None)</code>","text":"<p>Initialize clusters for k-means clustering algorithm.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>The input data array or DataFrame.</p> required <code>n_clusters</code> <code>int</code> <p>The number of clusters to initialize.</p> required <code>random_state</code> <code>int</code> <p>The seed value for random number generation (default: None).</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The initialized cluster centroids.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If the data type is not supported.</p> Source code in <code>src/cedskmeans/_map_reduce/_utils.py</code> <pre><code>def initialize_clusters(\n    data: np.ndarray, n_clusters: int, random_state: int = None\n) -&gt; np.ndarray:\n    \"\"\"\n    Initialize clusters for k-means clustering algorithm.\n\n    Args:\n        data (np.ndarray): The input data array or DataFrame.\n        n_clusters (int): The number of clusters to initialize.\n        random_state (int, optional): The seed value for random number generation (default: None).\n\n    Returns:\n        np.ndarray: The initialized cluster centroids.\n\n    Raises:\n        TypeError: If the data type is not supported.\n\n    \"\"\"\n    if isinstance(data, np.ndarray):\n        data_c = data.copy()\n    else:\n        raise TypeError(\"Data type not supported!\")\n\n    centroids, _ = kmeans_plusplus(data_c, n_clusters, random_state=random_state)\n    return centroids\n</code></pre>"},{"location":"#cedskmeans._mapreduce_kmeans.run_kmean_map_reduce","title":"<code>run_kmean_map_reduce(X, **kwargs)</code>","text":"<p>Run the KMeansMapReduce class. This is a workaround for the bug in sklearn get_params() function that prevents us from using the ray.remote decorator.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>DataFrame</code> <p>Training instances to cluster  of shape (n_samples, n_features). It must be noted that the data will be converted to C ordering, which will cause a memory copy if the given data is not C-contiguous. If a sparse matrix is passed, a copy will be made if it\u2019s not in CSR format.</p> required <p>Returns:</p> Name Type Description <code>kmeans</code> <code>KMeansMapReduce</code> <p>Fitted estimator.</p> Source code in <code>src/cedskmeans/_mapreduce_kmeans.py</code> <pre><code>@ray.remote(num_cpus=1)\ndef run_kmean_map_reduce(X, **kwargs) -&gt; KMeansMapReduce:\n    \"\"\"\n    Run the KMeansMapReduce class.\n    This is a workaround for the bug in sklearn get_params() function that prevents us from using the ray.remote decorator.\n\n    Args:\n        X (pd.DataFrame): Training instances to cluster  of shape (n_samples, n_features). It must be noted that the data will be converted to C ordering, which will cause a memory copy if the given data is not C-contiguous. If a sparse matrix is passed, a copy will be made if it's not in CSR format.\n\n    Returns:\n        kmeans (KMeansMapReduce): Fitted estimator.\n    \"\"\"\n    kmeans = KMeansMapReduce(\n        **kwargs,\n    )\n    kmeans.fit(X)\n    return kmeans\n</code></pre>"},{"location":"#cedskmeans._mapreduce_kmeans.split_data","title":"<code>split_data(data_frame, num_splits=3, random_seed=None)</code>","text":"<p>Splits a pandas DataFrame into multiple subsets.</p> <p>Parameters:</p> Name Type Description Default <code>data_frame</code> <code>DataFrame</code> <p>The input DataFrame to be split.</p> required <code>num_splits</code> <code>int</code> <p>The number of subsets to create (default: 3).</p> <code>3</code> <code>random_seed</code> <code>int</code> <p>The seed value for random number generation (default: None).</p> <code>None</code> <p>Returns:</p> Type Description <code>tuple[DataFrame, ...]</code> <p>A tuple of DataFrame subsets obtained by splitting the input DataFrame.</p> Source code in <code>src/cedskmeans/_map_reduce/_utils.py</code> <pre><code>def split_data(\n    data_frame: pd.DataFrame, num_splits: int = 3, random_seed: int = None\n) -&gt; tuple[pd.DataFrame, ...]:\n    \"\"\"\n    Splits a pandas DataFrame into multiple subsets.\n\n    Args:\n        data_frame: The input DataFrame to be split.\n        num_splits: The number of subsets to create (default: 3).\n        random_seed: The seed value for random number generation (default: None).\n\n    Returns:\n        A tuple of DataFrame subsets obtained by splitting the input DataFrame.\n\n    \"\"\"\n    np.random.seed(random_seed)\n    permutation = np.random.permutation(data_frame.index)\n    num_rows = len(data_frame.index)\n    split_points = np.linspace(0, num_rows, num_splits + 1, dtype=int)\n    data_splits = [\n        data_frame.iloc[permutation[split_points[i] : split_points[i + 1]]]\n        for i in range(num_splits)\n    ]\n    return tuple(data_splits)\n</code></pre>"},{"location":"#mapper-and-reducer-classes","title":"Mapper and Reducer Classes","text":""},{"location":"#cedskmeans._map_reduce._mapper.KMeansMap","title":"<code>KMeansMap</code>","text":"<p>A remote Ray class for performing K-means clustering map tasks.</p> <p>Parameters:</p> Name Type Description Default <code>items</code> <code>ndarray</code> <p>The input array of items.</p> required <code>num_clusters</code> <code>int</code> <p>The number of clusters (default: 1).</p> <code>1</code> <p>Attributes:</p> Name Type Description <code>items</code> <code>ndarray</code> <p>The input array of items.</p> <code>num_clusters</code> <code>int</code> <p>The number of clusters.</p> <code>cluster_assignments</code> <code>ndarray</code> <p>The array to store cluster assignments.</p> <code>distances_matrix</code> <code>ndarray</code> <p>The matrix containing pre-calculated distances between centroids.</p> Source code in <code>src/cedskmeans/_map_reduce/_mapper.py</code> <pre><code>@ray.remote(num_cpus=1)\nclass KMeansMap:\n    \"\"\"\n    A remote Ray class for performing K-means clustering map tasks.\n\n    Args:\n        items (np.ndarray): The input array of items.\n        num_clusters (int, optional): The number of clusters (default: 1).\n\n    Attributes:\n        items (np.ndarray): The input array of items.\n        num_clusters (int): The number of clusters.\n        cluster_assignments (np.ndarray): The array to store cluster assignments.\n        distances_matrix (np.ndarray): The matrix containing pre-calculated distances between centroids.\n    \"\"\"\n\n    centroids = 0\n\n    def __init__(self, items: np.ndarray, num_clusters: int = 1):\n        self.items = items\n        self.num_clusters = num_clusters\n        self.cluster_assignments = None\n        self.centroids = None\n        self.distances_matrix = None\n\n    def communicate_centroids(self, centroids: np.ndarray):\n        \"\"\"\n        Communicates the centroids to the KMeansMap instance.\n\n        Args:\n            centroids (np.ndarray): The centroids to be communicated.\n        \"\"\"\n        self.centroids = centroids\n\n    def communicate_distances(self, distances_matrix: np.ndarray):\n        \"\"\"\n        Communicates the distances matrix to the KMeansMap instance.\n\n        Args:\n            distances_matrix (np.ndarray): The distances matrix to be communicated.\n        \"\"\"\n        self.distances_matrix = distances_matrix\n\n    @staticmethod\n    def calculate_distance(point_a: np.ndarray, point_b: np.ndarray) -&gt; float:\n        \"\"\"\n        Calculates the distance between two points.\n\n        Args:\n            point_a (np.ndarray): The first point.\n            point_b (np.ndarray): The second point.\n\n        Returns:\n            float: The distance between the two points.\n        \"\"\"\n        return np.linalg.norm(point_a - point_b)\n\n    def read_cluster_assignments(self) -&gt; np.ndarray:\n        \"\"\"\n        Reads the cluster assignments.\n\n        Returns:\n            np.ndarray: The cluster assignments.\n        \"\"\"\n        return self.cluster_assignments\n\n    def read_items(self) -&gt; np.ndarray:\n        \"\"\"\n        Reads the input array of items.\n\n        Returns:\n            np.ndarray: The input array of items\n        \"\"\"\n        return self.items\n\n    def assign_clusters(self) -&gt; np.ndarray:\n        \"\"\"\n        Assigns clusters to each item.\n\n        Returns:\n            np.ndarray: The cluster assignments.\n        \"\"\"\n        num_items = self.items.shape[0]\n        self.cluster_assignments = np.zeros((num_items, 2))\n\n        for i in range(num_items):\n            min_index, min_distance = KMeansMap.find_closest_centroid(\n                self.num_clusters, self.centroids, self.items, i, self.distances_matrix\n            )\n            self.cluster_assignments[i, :] = min_index, min_distance\n\n        return self.cluster_assignments\n\n    @staticmethod\n    def find_closest_centroid(\n        num_clusters: int,\n        centroids: np.ndarray,\n        items: np.ndarray,\n        item_index: int,\n        distances_matrix: np.ndarray,\n    ) -&gt; tuple[int, float]:\n        \"\"\"\n        Find the index of the closest centroid to the given item.\n\n        Args:\n            num_clusters (int): The number of centroids.\n            centroids (np.ndarray): An array of centroid coordinates.\n            items (np.ndarray): An array of item coordinates.\n            item_index (int): Index of the item to compare.\n            distances_matrix (np.ndarray): Matrix containing pre-calculated distances between centroids.\n\n        Returns:\n            tuple[int, float]: Index of the closest centroid and the corresponding distance.\n        \"\"\"\n        best_distance = np.inf\n        best_index = -1\n        j = 0\n        num_centroids = centroids.shape[0]\n\n        while j &lt; num_centroids:\n            center = centroids[j]\n            distance = np.linalg.norm(center - items[item_index])\n\n            if distance &lt; best_distance:\n                best_distance = distance\n                best_index = j\n\n            if j &lt;= num_clusters - 2 and 2 * distance &lt;= distances_matrix[j, j + 1]:\n                j += 1\n\n            j += 1\n\n        return best_index, best_distance\n</code></pre>"},{"location":"#cedskmeans._map_reduce._mapper.KMeansMap.assign_clusters","title":"<code>assign_clusters()</code>","text":"<p>Assigns clusters to each item.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The cluster assignments.</p> Source code in <code>src/cedskmeans/_map_reduce/_mapper.py</code> <pre><code>def assign_clusters(self) -&gt; np.ndarray:\n    \"\"\"\n    Assigns clusters to each item.\n\n    Returns:\n        np.ndarray: The cluster assignments.\n    \"\"\"\n    num_items = self.items.shape[0]\n    self.cluster_assignments = np.zeros((num_items, 2))\n\n    for i in range(num_items):\n        min_index, min_distance = KMeansMap.find_closest_centroid(\n            self.num_clusters, self.centroids, self.items, i, self.distances_matrix\n        )\n        self.cluster_assignments[i, :] = min_index, min_distance\n\n    return self.cluster_assignments\n</code></pre>"},{"location":"#cedskmeans._map_reduce._mapper.KMeansMap.calculate_distance","title":"<code>calculate_distance(point_a, point_b)</code>  <code>staticmethod</code>","text":"<p>Calculates the distance between two points.</p> <p>Parameters:</p> Name Type Description Default <code>point_a</code> <code>ndarray</code> <p>The first point.</p> required <code>point_b</code> <code>ndarray</code> <p>The second point.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The distance between the two points.</p> Source code in <code>src/cedskmeans/_map_reduce/_mapper.py</code> <pre><code>@staticmethod\ndef calculate_distance(point_a: np.ndarray, point_b: np.ndarray) -&gt; float:\n    \"\"\"\n    Calculates the distance between two points.\n\n    Args:\n        point_a (np.ndarray): The first point.\n        point_b (np.ndarray): The second point.\n\n    Returns:\n        float: The distance between the two points.\n    \"\"\"\n    return np.linalg.norm(point_a - point_b)\n</code></pre>"},{"location":"#cedskmeans._map_reduce._mapper.KMeansMap.communicate_centroids","title":"<code>communicate_centroids(centroids)</code>","text":"<p>Communicates the centroids to the KMeansMap instance.</p> <p>Parameters:</p> Name Type Description Default <code>centroids</code> <code>ndarray</code> <p>The centroids to be communicated.</p> required Source code in <code>src/cedskmeans/_map_reduce/_mapper.py</code> <pre><code>def communicate_centroids(self, centroids: np.ndarray):\n    \"\"\"\n    Communicates the centroids to the KMeansMap instance.\n\n    Args:\n        centroids (np.ndarray): The centroids to be communicated.\n    \"\"\"\n    self.centroids = centroids\n</code></pre>"},{"location":"#cedskmeans._map_reduce._mapper.KMeansMap.communicate_distances","title":"<code>communicate_distances(distances_matrix)</code>","text":"<p>Communicates the distances matrix to the KMeansMap instance.</p> <p>Parameters:</p> Name Type Description Default <code>distances_matrix</code> <code>ndarray</code> <p>The distances matrix to be communicated.</p> required Source code in <code>src/cedskmeans/_map_reduce/_mapper.py</code> <pre><code>def communicate_distances(self, distances_matrix: np.ndarray):\n    \"\"\"\n    Communicates the distances matrix to the KMeansMap instance.\n\n    Args:\n        distances_matrix (np.ndarray): The distances matrix to be communicated.\n    \"\"\"\n    self.distances_matrix = distances_matrix\n</code></pre>"},{"location":"#cedskmeans._map_reduce._mapper.KMeansMap.find_closest_centroid","title":"<code>find_closest_centroid(num_clusters, centroids, items, item_index, distances_matrix)</code>  <code>staticmethod</code>","text":"<p>Find the index of the closest centroid to the given item.</p> <p>Parameters:</p> Name Type Description Default <code>num_clusters</code> <code>int</code> <p>The number of centroids.</p> required <code>centroids</code> <code>ndarray</code> <p>An array of centroid coordinates.</p> required <code>items</code> <code>ndarray</code> <p>An array of item coordinates.</p> required <code>item_index</code> <code>int</code> <p>Index of the item to compare.</p> required <code>distances_matrix</code> <code>ndarray</code> <p>Matrix containing pre-calculated distances between centroids.</p> required <p>Returns:</p> Type Description <code>tuple[int, float]</code> <p>tuple[int, float]: Index of the closest centroid and the corresponding distance.</p> Source code in <code>src/cedskmeans/_map_reduce/_mapper.py</code> <pre><code>@staticmethod\ndef find_closest_centroid(\n    num_clusters: int,\n    centroids: np.ndarray,\n    items: np.ndarray,\n    item_index: int,\n    distances_matrix: np.ndarray,\n) -&gt; tuple[int, float]:\n    \"\"\"\n    Find the index of the closest centroid to the given item.\n\n    Args:\n        num_clusters (int): The number of centroids.\n        centroids (np.ndarray): An array of centroid coordinates.\n        items (np.ndarray): An array of item coordinates.\n        item_index (int): Index of the item to compare.\n        distances_matrix (np.ndarray): Matrix containing pre-calculated distances between centroids.\n\n    Returns:\n        tuple[int, float]: Index of the closest centroid and the corresponding distance.\n    \"\"\"\n    best_distance = np.inf\n    best_index = -1\n    j = 0\n    num_centroids = centroids.shape[0]\n\n    while j &lt; num_centroids:\n        center = centroids[j]\n        distance = np.linalg.norm(center - items[item_index])\n\n        if distance &lt; best_distance:\n            best_distance = distance\n            best_index = j\n\n        if j &lt;= num_clusters - 2 and 2 * distance &lt;= distances_matrix[j, j + 1]:\n            j += 1\n\n        j += 1\n\n    return best_index, best_distance\n</code></pre>"},{"location":"#cedskmeans._map_reduce._mapper.KMeansMap.read_cluster_assignments","title":"<code>read_cluster_assignments()</code>","text":"<p>Reads the cluster assignments.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The cluster assignments.</p> Source code in <code>src/cedskmeans/_map_reduce/_mapper.py</code> <pre><code>def read_cluster_assignments(self) -&gt; np.ndarray:\n    \"\"\"\n    Reads the cluster assignments.\n\n    Returns:\n        np.ndarray: The cluster assignments.\n    \"\"\"\n    return self.cluster_assignments\n</code></pre>"},{"location":"#cedskmeans._map_reduce._mapper.KMeansMap.read_items","title":"<code>read_items()</code>","text":"<p>Reads the input array of items.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The input array of items</p> Source code in <code>src/cedskmeans/_map_reduce/_mapper.py</code> <pre><code>def read_items(self) -&gt; np.ndarray:\n    \"\"\"\n    Reads the input array of items.\n\n    Returns:\n        np.ndarray: The input array of items\n    \"\"\"\n    return self.items\n</code></pre>"},{"location":"#cedskmeans._map_reduce._reducer.KMeansReduce","title":"<code>KMeansReduce</code>","text":"<p>Class representing a K-Means reducer.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>int</code> <p>The value associated with the reducer.</p> required <code>n_features</code> <code>int</code> <p>The number of features in the data.</p> required <code>*kmeans_maps</code> <code>list[ActorHandle]</code> <p>Variable-length arguments representing K-Means mappers.</p> <code>()</code> <p>Attributes:</p> Name Type Description <code>value</code> <code>int</code> <p>The value associated with the reducer.</p> <code>kmeans_maps</code> <code>list[ActorHandle]</code> <p>List of K-Means mapper handles.</p> <code>centroid</code> <code>None | ndarray</code> <p>The computed centroid of the cluster.</p> <code>cluster_output</code> <code>ndarray</code> <p>The combined cluster output.</p> <code>cost</code> <code>float</code> <p>The cost of the clustering.</p> Source code in <code>src/cedskmeans/_map_reduce/_reducer.py</code> <pre><code>@ray.remote(num_cpus=1)\nclass KMeansReduce:\n    \"\"\"\n    Class representing a K-Means reducer.\n\n    Args:\n        value (int): The value associated with the reducer.\n        n_features (int): The number of features in the data.\n        *kmeans_maps (list[ray.actor.ActorHandle]): Variable-length arguments representing K-Means mappers.\n\n    Attributes:\n        value (int): The value associated with the reducer.\n        kmeans_maps (list[ray.actor.ActorHandle]): List of K-Means mapper handles.\n        centroid (None | np.ndarray): The computed centroid of the cluster.\n        cluster_output (np.ndarray): The combined cluster output.\n        cost (float): The cost of the clustering.\n    \"\"\"\n\n    def __init__(\n        self, value: int, n_features: int, *kmeans_maps: ray.actor.ActorHandle\n    ) -&gt; None:\n        self.value = value\n        self.kmeans_maps = kmeans_maps\n        self.centroid = None\n        self.cluster_output = np.zeros((1, n_features))\n        self.cost = 0\n\n    def read(self) -&gt; int:\n        \"\"\"\n        Get the value associated with the reducer.\n\n        Returns:\n            int: The value associated with the reducer.\n        \"\"\"\n        return self.value\n\n    def read_cost(self) -&gt; float:\n        \"\"\"\n        Get the cost of the clustering.\n\n        Returns:\n            float: The cost of the clustering.\n        \"\"\"\n        return self.cost\n\n    def update_cluster(self) -&gt; None | np.ndarray:\n        \"\"\"\n        Update the cluster by computing the centroid. This method collects all the\n        references to the cluster assignments and mapper items before calling ray.get().\n\n        Returns:\n            None | np.ndarray: The computed centroid, or None if an error occurs.\n        \"\"\"\n        cluster_assignment_refs = [\n            kmeans_map.assign_clusters.remote() for kmeans_map in self.kmeans_maps\n        ]\n        mapper_items_refs = [\n            kmeans_map.read_items.remote() for kmeans_map in self.kmeans_maps\n        ]\n\n        cluster_assignments = ray.get(cluster_assignment_refs)\n\n        self.cost = np.sum(\n            [\n                np.sum(cluster_assignment[:, 1])\n                for cluster_assignment in cluster_assignments\n            ]\n        )\n        cluster_indices_all = [\n            np.where(cluster_assignment[:, 0] == self.value)[0]\n            for cluster_assignment in cluster_assignments\n        ]\n        mapper_items_all = ray.get(mapper_items_refs)\n        self.cluster_output = np.concatenate(\n            [\n                mapper_items[cluster_indices]\n                for mapper_items, cluster_indices, in zip(\n                    mapper_items_all, cluster_indices_all\n                )\n            ]\n        )\n        self.centroid = np.mean(self.cluster_output, axis=0)\n        return self.centroid\n</code></pre>"},{"location":"#cedskmeans._map_reduce._reducer.KMeansReduce.read","title":"<code>read()</code>","text":"<p>Get the value associated with the reducer.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The value associated with the reducer.</p> Source code in <code>src/cedskmeans/_map_reduce/_reducer.py</code> <pre><code>def read(self) -&gt; int:\n    \"\"\"\n    Get the value associated with the reducer.\n\n    Returns:\n        int: The value associated with the reducer.\n    \"\"\"\n    return self.value\n</code></pre>"},{"location":"#cedskmeans._map_reduce._reducer.KMeansReduce.read_cost","title":"<code>read_cost()</code>","text":"<p>Get the cost of the clustering.</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The cost of the clustering.</p> Source code in <code>src/cedskmeans/_map_reduce/_reducer.py</code> <pre><code>def read_cost(self) -&gt; float:\n    \"\"\"\n    Get the cost of the clustering.\n\n    Returns:\n        float: The cost of the clustering.\n    \"\"\"\n    return self.cost\n</code></pre>"},{"location":"#cedskmeans._map_reduce._reducer.KMeansReduce.update_cluster","title":"<code>update_cluster()</code>","text":"<p>Update the cluster by computing the centroid. This method collects all the references to the cluster assignments and mapper items before calling ray.get().</p> <p>Returns:</p> Type Description <code>None | ndarray</code> <p>None | np.ndarray: The computed centroid, or None if an error occurs.</p> Source code in <code>src/cedskmeans/_map_reduce/_reducer.py</code> <pre><code>def update_cluster(self) -&gt; None | np.ndarray:\n    \"\"\"\n    Update the cluster by computing the centroid. This method collects all the\n    references to the cluster assignments and mapper items before calling ray.get().\n\n    Returns:\n        None | np.ndarray: The computed centroid, or None if an error occurs.\n    \"\"\"\n    cluster_assignment_refs = [\n        kmeans_map.assign_clusters.remote() for kmeans_map in self.kmeans_maps\n    ]\n    mapper_items_refs = [\n        kmeans_map.read_items.remote() for kmeans_map in self.kmeans_maps\n    ]\n\n    cluster_assignments = ray.get(cluster_assignment_refs)\n\n    self.cost = np.sum(\n        [\n            np.sum(cluster_assignment[:, 1])\n            for cluster_assignment in cluster_assignments\n        ]\n    )\n    cluster_indices_all = [\n        np.where(cluster_assignment[:, 0] == self.value)[0]\n        for cluster_assignment in cluster_assignments\n    ]\n    mapper_items_all = ray.get(mapper_items_refs)\n    self.cluster_output = np.concatenate(\n        [\n            mapper_items[cluster_indices]\n            for mapper_items, cluster_indices, in zip(\n                mapper_items_all, cluster_indices_all\n            )\n        ]\n    )\n    self.centroid = np.mean(self.cluster_output, axis=0)\n    return self.centroid\n</code></pre>"},{"location":"#utility-methods","title":"Utility Methods","text":""},{"location":"#cedskmeans._map_reduce._utils.KMeansReduce","title":"<code>KMeansReduce</code>","text":"<p>Class representing a K-Means reducer.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>int</code> <p>The value associated with the reducer.</p> required <code>n_features</code> <code>int</code> <p>The number of features in the data.</p> required <code>*kmeans_maps</code> <code>list[ActorHandle]</code> <p>Variable-length arguments representing K-Means mappers.</p> <code>()</code> <p>Attributes:</p> Name Type Description <code>value</code> <code>int</code> <p>The value associated with the reducer.</p> <code>kmeans_maps</code> <code>list[ActorHandle]</code> <p>List of K-Means mapper handles.</p> <code>centroid</code> <code>None | ndarray</code> <p>The computed centroid of the cluster.</p> <code>cluster_output</code> <code>ndarray</code> <p>The combined cluster output.</p> <code>cost</code> <code>float</code> <p>The cost of the clustering.</p> Source code in <code>src/cedskmeans/_map_reduce/_reducer.py</code> <pre><code>@ray.remote(num_cpus=1)\nclass KMeansReduce:\n    \"\"\"\n    Class representing a K-Means reducer.\n\n    Args:\n        value (int): The value associated with the reducer.\n        n_features (int): The number of features in the data.\n        *kmeans_maps (list[ray.actor.ActorHandle]): Variable-length arguments representing K-Means mappers.\n\n    Attributes:\n        value (int): The value associated with the reducer.\n        kmeans_maps (list[ray.actor.ActorHandle]): List of K-Means mapper handles.\n        centroid (None | np.ndarray): The computed centroid of the cluster.\n        cluster_output (np.ndarray): The combined cluster output.\n        cost (float): The cost of the clustering.\n    \"\"\"\n\n    def __init__(\n        self, value: int, n_features: int, *kmeans_maps: ray.actor.ActorHandle\n    ) -&gt; None:\n        self.value = value\n        self.kmeans_maps = kmeans_maps\n        self.centroid = None\n        self.cluster_output = np.zeros((1, n_features))\n        self.cost = 0\n\n    def read(self) -&gt; int:\n        \"\"\"\n        Get the value associated with the reducer.\n\n        Returns:\n            int: The value associated with the reducer.\n        \"\"\"\n        return self.value\n\n    def read_cost(self) -&gt; float:\n        \"\"\"\n        Get the cost of the clustering.\n\n        Returns:\n            float: The cost of the clustering.\n        \"\"\"\n        return self.cost\n\n    def update_cluster(self) -&gt; None | np.ndarray:\n        \"\"\"\n        Update the cluster by computing the centroid. This method collects all the\n        references to the cluster assignments and mapper items before calling ray.get().\n\n        Returns:\n            None | np.ndarray: The computed centroid, or None if an error occurs.\n        \"\"\"\n        cluster_assignment_refs = [\n            kmeans_map.assign_clusters.remote() for kmeans_map in self.kmeans_maps\n        ]\n        mapper_items_refs = [\n            kmeans_map.read_items.remote() for kmeans_map in self.kmeans_maps\n        ]\n\n        cluster_assignments = ray.get(cluster_assignment_refs)\n\n        self.cost = np.sum(\n            [\n                np.sum(cluster_assignment[:, 1])\n                for cluster_assignment in cluster_assignments\n            ]\n        )\n        cluster_indices_all = [\n            np.where(cluster_assignment[:, 0] == self.value)[0]\n            for cluster_assignment in cluster_assignments\n        ]\n        mapper_items_all = ray.get(mapper_items_refs)\n        self.cluster_output = np.concatenate(\n            [\n                mapper_items[cluster_indices]\n                for mapper_items, cluster_indices, in zip(\n                    mapper_items_all, cluster_indices_all\n                )\n            ]\n        )\n        self.centroid = np.mean(self.cluster_output, axis=0)\n        return self.centroid\n</code></pre>"},{"location":"#cedskmeans._map_reduce._utils.KMeansReduce.read","title":"<code>read()</code>","text":"<p>Get the value associated with the reducer.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The value associated with the reducer.</p> Source code in <code>src/cedskmeans/_map_reduce/_reducer.py</code> <pre><code>def read(self) -&gt; int:\n    \"\"\"\n    Get the value associated with the reducer.\n\n    Returns:\n        int: The value associated with the reducer.\n    \"\"\"\n    return self.value\n</code></pre>"},{"location":"#cedskmeans._map_reduce._utils.KMeansReduce.read_cost","title":"<code>read_cost()</code>","text":"<p>Get the cost of the clustering.</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The cost of the clustering.</p> Source code in <code>src/cedskmeans/_map_reduce/_reducer.py</code> <pre><code>def read_cost(self) -&gt; float:\n    \"\"\"\n    Get the cost of the clustering.\n\n    Returns:\n        float: The cost of the clustering.\n    \"\"\"\n    return self.cost\n</code></pre>"},{"location":"#cedskmeans._map_reduce._utils.KMeansReduce.update_cluster","title":"<code>update_cluster()</code>","text":"<p>Update the cluster by computing the centroid. This method collects all the references to the cluster assignments and mapper items before calling ray.get().</p> <p>Returns:</p> Type Description <code>None | ndarray</code> <p>None | np.ndarray: The computed centroid, or None if an error occurs.</p> Source code in <code>src/cedskmeans/_map_reduce/_reducer.py</code> <pre><code>def update_cluster(self) -&gt; None | np.ndarray:\n    \"\"\"\n    Update the cluster by computing the centroid. This method collects all the\n    references to the cluster assignments and mapper items before calling ray.get().\n\n    Returns:\n        None | np.ndarray: The computed centroid, or None if an error occurs.\n    \"\"\"\n    cluster_assignment_refs = [\n        kmeans_map.assign_clusters.remote() for kmeans_map in self.kmeans_maps\n    ]\n    mapper_items_refs = [\n        kmeans_map.read_items.remote() for kmeans_map in self.kmeans_maps\n    ]\n\n    cluster_assignments = ray.get(cluster_assignment_refs)\n\n    self.cost = np.sum(\n        [\n            np.sum(cluster_assignment[:, 1])\n            for cluster_assignment in cluster_assignments\n        ]\n    )\n    cluster_indices_all = [\n        np.where(cluster_assignment[:, 0] == self.value)[0]\n        for cluster_assignment in cluster_assignments\n    ]\n    mapper_items_all = ray.get(mapper_items_refs)\n    self.cluster_output = np.concatenate(\n        [\n            mapper_items[cluster_indices]\n            for mapper_items, cluster_indices, in zip(\n                mapper_items_all, cluster_indices_all\n            )\n        ]\n    )\n    self.centroid = np.mean(self.cluster_output, axis=0)\n    return self.centroid\n</code></pre>"},{"location":"#cedskmeans._map_reduce._utils.calculate_distance_matrix","title":"<code>calculate_distance_matrix(center)</code>","text":"<p>Calculate the distance matrix between points in the given center array.</p> <p>Parameters:</p> Name Type Description Default <code>center</code> <code>ndarray</code> <p>Array of points representing the center.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The distance matrix between points in the center array.</p> Source code in <code>src/cedskmeans/_map_reduce/_utils.py</code> <pre><code>def calculate_distance_matrix(center: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Calculate the distance matrix between points in the given center array.\n\n    Args:\n        center (np.ndarray): Array of points representing the center.\n\n    Returns:\n        np.ndarray: The distance matrix between points in the center array.\n\n    \"\"\"\n    n = center.shape[0]\n    distance_matrix = np.empty((n, n))\n    for i in range(n - 1):\n        distance_matrix[i, i + 1] = np.linalg.norm(center[i + 1, :] - center[i, :])\n    return distance_matrix\n</code></pre>"},{"location":"#cedskmeans._map_reduce._utils.create_new_cluster","title":"<code>create_new_cluster(reducers)</code>","text":"<p>Creates a new cluster by combining clusters from multiple KMeansReduce objects.</p> <p>Parameters:</p> Name Type Description Default <code>reducers</code> <code>list[KMeansReduce]</code> <p>A list of KMeansReduce objects.</p> required <code>n_features</code> <p>The number of features in the dataset.</p> required <p>Returns:</p> Type Description <code>tuple[ndarray, float]</code> <p>A tuple containing the new cluster as a NumPy array and the total cost.</p> Source code in <code>src/cedskmeans/_map_reduce/_utils.py</code> <pre><code>def create_new_cluster(reducers: list[KMeansReduce]) -&gt; tuple[np.ndarray, float]:\n    \"\"\"\n    Creates a new cluster by combining clusters from multiple KMeansReduce objects.\n\n    Args:\n        reducers: A list of KMeansReduce objects.\n        n_features: The number of features in the dataset.\n\n    Returns:\n        A tuple containing the new cluster as a NumPy array and the total cost.\n\n    \"\"\"\n    cluster_refs = []\n    cost_refs = []\n    for reducer in reducers:\n        cluster_refs.append(reducer.update_cluster.remote())\n        cost_refs.append(reducer.read_cost.remote())\n    # TODO: In the KMeansReduce class, the update_cluster method should be first\n    # called and only at its conclusion should the read_cost method be called.\n    # So, should the cost_refs be gathered after ray.get(cluster_refs)?\n    combined_cluster = ray.get(cluster_refs)\n    total_cost = ray.get(cost_refs)\n    return np.array(combined_cluster), np.sum(total_cost)\n</code></pre>"},{"location":"#cedskmeans._map_reduce._utils.fast_squared_distance","title":"<code>fast_squared_distance(center, point, epsilon=0.0001, precision=1e-06)</code>","text":"<p>Calculates the squared distance between two vectors, taking advantage of optimization techniques.</p> <p>Parameters:</p> Name Type Description Default <code>center</code> <code>ndarray</code> <p>The center vector as a NumPy array.</p> required <code>point</code> <code>ndarray</code> <p>The point vector as a NumPy array.</p> required <code>epsilon</code> <code>float</code> <p>The epsilon value for the precision bound (default: 1e-4).</p> <code>0.0001</code> <code>precision</code> <code>float</code> <p>The precision threshold for choosing the calculation method (default: 1e-6).</p> <code>1e-06</code> <p>Returns:</p> Type Description <code>float</code> <p>The squared distance between the center and point vectors.</p> Source code in <code>src/cedskmeans/_map_reduce/_utils.py</code> <pre><code>def fast_squared_distance(\n    center: np.ndarray,\n    point: np.ndarray,\n    epsilon: float = 1e-4,\n    precision: float = 1e-6,\n) -&gt; float:\n    \"\"\"\n    Calculates the squared distance between two vectors, taking advantage of optimization techniques.\n\n    Args:\n        center: The center vector as a NumPy array.\n        point: The point vector as a NumPy array.\n        epsilon: The epsilon value for the precision bound (default: 1e-4).\n        precision: The precision threshold for choosing the calculation method (default: 1e-6).\n\n    Returns:\n        The squared distance between the center and point vectors.\n\n    \"\"\"\n    center_norm = np.linalg.norm(center)\n    point_norm = np.linalg.norm(point)\n    sum_squared_norm = center_norm**2 + point_norm**2\n    norm_diff = center_norm - point_norm\n\n    bound = 2.0 * epsilon * sum_squared_norm / (norm_diff**2 + epsilon)\n    squared_distance = 0.0\n\n    if bound &lt; precision:\n        squared_distance = sum_squared_norm - 2.0 * np.dot(center, point)\n    else:\n        squared_distance = np.linalg.norm(center - point)\n\n    return squared_distance\n</code></pre>"},{"location":"#cedskmeans._map_reduce._utils.has_cluster_changed","title":"<code>has_cluster_changed(new_centers, old_centers, epsilon=0.0001)</code>","text":"<p>Checks if the cluster centers have changed based on a given epsilon threshold.</p> <p>Parameters:</p> Name Type Description Default <code>new_centers</code> <code>ndarray</code> <p>The new cluster centers as a NumPy array.</p> required <code>old_centers</code> <code>ndarray</code> <p>The old cluster centers as a NumPy array.</p> required <code>epsilon</code> <code>float</code> <p>The threshold value for considering a change (default: 1e-4).</p> <code>0.0001</code> <p>Returns:</p> Type Description <code>tuple[bool, float]</code> <p>A tuple containing a boolean flag indicating if the clusters have changed and the total cost.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the dimensions of new_centers and old_centers do not match.</p> Source code in <code>src/cedskmeans/_map_reduce/_utils.py</code> <pre><code>def has_cluster_changed(\n    new_centers: np.ndarray, old_centers: np.ndarray, epsilon: float = 1e-4\n) -&gt; tuple[bool, float]:\n    \"\"\"\n    Checks if the cluster centers have changed based on a given epsilon threshold.\n\n    Args:\n        new_centers: The new cluster centers as a NumPy array.\n        old_centers: The old cluster centers as a NumPy array.\n        epsilon: The threshold value for considering a change (default: 1e-4).\n\n    Returns:\n        A tuple containing a boolean flag indicating if the clusters have changed and the total cost.\n\n    Raises:\n        ValueError: If the dimensions of new_centers and old_centers do not match.\n\n    \"\"\"\n    if new_centers.shape[0] != old_centers.shape[0]:\n        raise ValueError(\n            \"Error: Dimensions of new_centers and old_centers do not match!\"\n        )\n\n    n = new_centers.shape[0]\n    total_cost = 0.0\n    changed = False\n\n    for i in range(n):\n        squared_diff = fast_squared_distance(new_centers[i], old_centers[i])\n        if squared_diff &gt; epsilon**2:\n            changed = True\n        total_cost += squared_diff\n\n    return changed, total_cost\n</code></pre>"},{"location":"#cedskmeans._map_reduce._utils.initialize_clusters","title":"<code>initialize_clusters(data, n_clusters, random_state=None)</code>","text":"<p>Initialize clusters for k-means clustering algorithm.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>The input data array or DataFrame.</p> required <code>n_clusters</code> <code>int</code> <p>The number of clusters to initialize.</p> required <code>random_state</code> <code>int</code> <p>The seed value for random number generation (default: None).</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The initialized cluster centroids.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If the data type is not supported.</p> Source code in <code>src/cedskmeans/_map_reduce/_utils.py</code> <pre><code>def initialize_clusters(\n    data: np.ndarray, n_clusters: int, random_state: int = None\n) -&gt; np.ndarray:\n    \"\"\"\n    Initialize clusters for k-means clustering algorithm.\n\n    Args:\n        data (np.ndarray): The input data array or DataFrame.\n        n_clusters (int): The number of clusters to initialize.\n        random_state (int, optional): The seed value for random number generation (default: None).\n\n    Returns:\n        np.ndarray: The initialized cluster centroids.\n\n    Raises:\n        TypeError: If the data type is not supported.\n\n    \"\"\"\n    if isinstance(data, np.ndarray):\n        data_c = data.copy()\n    else:\n        raise TypeError(\"Data type not supported!\")\n\n    centroids, _ = kmeans_plusplus(data_c, n_clusters, random_state=random_state)\n    return centroids\n</code></pre>"},{"location":"#cedskmeans._map_reduce._utils.split_data","title":"<code>split_data(data_frame, num_splits=3, random_seed=None)</code>","text":"<p>Splits a pandas DataFrame into multiple subsets.</p> <p>Parameters:</p> Name Type Description Default <code>data_frame</code> <code>DataFrame</code> <p>The input DataFrame to be split.</p> required <code>num_splits</code> <code>int</code> <p>The number of subsets to create (default: 3).</p> <code>3</code> <code>random_seed</code> <code>int</code> <p>The seed value for random number generation (default: None).</p> <code>None</code> <p>Returns:</p> Type Description <code>tuple[DataFrame, ...]</code> <p>A tuple of DataFrame subsets obtained by splitting the input DataFrame.</p> Source code in <code>src/cedskmeans/_map_reduce/_utils.py</code> <pre><code>def split_data(\n    data_frame: pd.DataFrame, num_splits: int = 3, random_seed: int = None\n) -&gt; tuple[pd.DataFrame, ...]:\n    \"\"\"\n    Splits a pandas DataFrame into multiple subsets.\n\n    Args:\n        data_frame: The input DataFrame to be split.\n        num_splits: The number of subsets to create (default: 3).\n        random_seed: The seed value for random number generation (default: None).\n\n    Returns:\n        A tuple of DataFrame subsets obtained by splitting the input DataFrame.\n\n    \"\"\"\n    np.random.seed(random_seed)\n    permutation = np.random.permutation(data_frame.index)\n    num_rows = len(data_frame.index)\n    split_points = np.linspace(0, num_rows, num_splits + 1, dtype=int)\n    data_splits = [\n        data_frame.iloc[permutation[split_points[i] : split_points[i + 1]]]\n        for i in range(num_splits)\n    ]\n    return tuple(data_splits)\n</code></pre>"},{"location":"home/","title":"CEDS DP K-Means Clustering","text":"<p>This repository contains the code for the CEDS Data Product K-Means Clustering. It follows the methodology proposed in papers [1] and [2].</p> <p>[1] Ravi, Nikhil, et al. \u201cDifferentially Private-Means Clustering Applied to Meter Data Analysis and Synthesis.\u201d IEEE Transactions on Smart Grid 13.6 (2022): 4801-4814. [2] Ravi, Nikhil, Anna Scaglione, and Sean Peisert. \u201cColored noise mechanism for differentially private clustering.\u201d arXiv preprint arXiv:2111.07850 (2021).</p>"},{"location":"home/#installation","title":"Installation","text":"<pre><code>pip install git+https://github.com/lbnl-cybersecurity/CEDSKMeans.git\n</code></pre>"},{"location":"home/#centralized-usage","title":"Centralized Usage","text":"<pre><code>from cedskmeans import DPKMeans\n\n# Import the data\nX = \"Import data here in the form of a numpy ndarray\"\n\n# Create a CEDSKMeans object\nkmeans = DPKMeans(\n    n_clusters=6,\n    epsilon=0.1,\n    delta=1e-5,\n    max_iter=1000\n)\nkmeans.fit(X)\n\n# Access the labels\nlabels = kmeans.labels_\n# Access the centroids\ncentroids = kmeans.cluster_centers_\n\n# Access the true labels\ntrue_labels = kmeans.true_labels_\n# Access the true centroids\ntrue_centroids = kmeans.true_cluster_centers_\n</code></pre>"},{"location":"home/#distributed-map-reduce-usage-requires-ray","title":"Distributed Map Reduce Usage (requires <code>ray</code>)","text":"<pre><code>from cedskmeans import run_kmean_map_reduce\nimport ray\n\n# Import the data\nX = \"Import data here in the form of a pandas dataframe\"\n\nray.init()\n# Create a CEDSKMeans object\nkmeans = run_kmean_map_reduce.remote(\n    X=X,\n    n_clusters=3,\n    n_mappers=2,\n    max_iter=1000,\n    epsilon=0.1, \n    delta=1e-5, \n)\nkmeans = ray.get(kmeans)\n\n# Access the labels\nlabels = kmeans.labels_ \n# Access the centroids\ncentroids = kmeans.cluster_centers_\n</code></pre>"},{"location":"home/#copyright-notice","title":"Copyright Notice","text":"<p>CEDS Differential Privacy (CEDSDP) Copyright (c) 2023, The Regents of the University of California, through Lawrence Berkeley National Laboratory (subject to receipt of any required approvals from the U.S. Dept. of Energy) and Cornell University. All rights reserved.</p> <p>If you have questions about your rights to use or distribute this software, please contact Berkeley Lab\u2019s Intellectual Property Office at IPO@lbl.gov.</p> <p>NOTICE.  This Software was developed under funding from the U.S. Department of Energy and the U.S. Government consequently retains certain rights.  As such, the U.S. Government has been granted for itself and others acting on its behalf a paid-up, nonexclusive, irrevocable, worldwide license in the Software to reproduce, distribute copies to the public, prepare derivative works, and perform publicly and display publicly, and to permit others to do so.</p>"}]}